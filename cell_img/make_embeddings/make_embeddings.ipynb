{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbSThipcULFS"
      },
      "outputs": [],
      "source": [
        "%pip install --quiet apache-beam[gcp,dataframe]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRXrURCrr3ut"
      },
      "outputs": [],
      "source": [
        "%pip install --quiet fsspec[gcs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "executionInfo": {
          "elapsed": 8493,
          "status": "ok",
          "timestamp": 1652915910191,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "JFzJfhHDvqHU"
      },
      "outputs": [],
      "source": [
        "# These imports will fail unless you restart the runtime after pip install.\n",
        "import os\n",
        "import apache_beam as beam\n",
        "import apache_beam.dataframe.convert\n",
        "import apache_beam.dataframe.io\n",
        "from apache_beam.options import pipeline_options\n",
        "from apache_beam.options.pipeline_options import GoogleCloudOptions\n",
        "from PIL import Image as PilImage\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import fsspec\n",
        "import tensorflow as tf\n",
        "import pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "executionInfo": {
          "elapsed": 196,
          "status": "ok",
          "timestamp": 1652915939427,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "7TVtf1LKV9DX"
      },
      "outputs": [],
      "source": [
        "# Length of the embedding vector for one image. Schema needs to know in advance.\n",
        "EMB_LEN = 2048\n",
        "\n",
        "class Embedder(beam.DoFn):\n",
        "\n",
        "  def setup(self):\n",
        "    import tensorflow as tf\n",
        "    # Input should be grayscale (not RGB) images. They should be uint16.\n",
        "    x = tf.keras.layers.Input([None, None], dtype=tf.uint16)\n",
        "    x = tf.image.convert_image_dtype(x, 'uint8')\n",
        "    x = tf.cast(x, tf.float32)\n",
        "    x = x[..., tf.newaxis]  # Add channels dimension.\n",
        "    x = tf.image.resize(x, [224, 224])\n",
        "    x = tf.image.grayscale_to_rgb(x)\n",
        "    x = tf.keras.applications.resnet50.preprocess_input(x)\n",
        "    self._model = tf.keras.applications.resnet50.ResNet50(\n",
        "            input_tensor=x,\n",
        "            input_shape=(224, 224, 3),\n",
        "            include_top=False,\n",
        "            weights=\"imagenet\",\n",
        "            pooling='avg')\n",
        "\n",
        "  def process(self, elem):\n",
        "    import numpy as np\n",
        "    if self._model is None:\n",
        "      self.create_model()\n",
        "    img = elem['image']\n",
        "    if len(img.shape) != 2:\n",
        "      raise ValueError('Grayscale image expected but shape was %s. img_path=%s' %\n",
        "                       (str(img.shape), elem['image_path']))\n",
        "    if img.dtype != np.uint16:\n",
        "      raise ValueError('Model expects uint16 image but was %s. img_path=%s' % \n",
        "                       (img.dtype, elem['image_path']))\n",
        "    img = np.expand_dims(img, axis=0) # Make batch dimension\n",
        "    # TODO: Consider making a batching DoFn for better efficiency.\n",
        "    emb = self._model.predict(img)\n",
        "    elem['embedding'] = np.squeeze(emb) # Remove batch dimension\n",
        "    return [elem]\n",
        "\n",
        "\n",
        "def load_img(elem):\n",
        "  import fsspec\n",
        "  from PIL import Image as PilImage\n",
        "  import numpy as np\n",
        "  path = elem['image_path']\n",
        "  with fsspec.open(path, mode='rb') as f:\n",
        "    im = PilImage.open(f)\n",
        "    array = np.asarray(im)\n",
        "  elem['image'] = array\n",
        "  return elem\n",
        "\n",
        "\n",
        "def to_row(elem, metadata_fields, emb_fields):\n",
        "  import apache_beam as beam\n",
        "  # Needs to match the schema in with_output_types\n",
        "  d = {k: elem[k] for k in metadata_fields}\n",
        "  if len(emb_fields) != len(elem['embedding']):\n",
        "    raise ValueError('Expected embedding length %d but it is %d.' %\n",
        "                     (len(emb_fields), len(elem['embedding'])))\n",
        "  for emb_name, emb_val in zip(emb_fields, elem['embedding']):\n",
        "    d[emb_name] = emb_val\n",
        "  return d\n",
        "\n",
        "\n",
        "def make_pipeline(image_metadata_path,\n",
        "                  output_path,\n",
        "                  num_output_shards=None,\n",
        "                  options=None):\n",
        "  # Read the header of the image_metadata csv file to know the columns.\n",
        "  with fsspec.open(image_metadata_path, mode='rb') as f:\n",
        "    header = list(pd.read_csv(f, nrows=1).columns)\n",
        "  if 'image_path' not in header:\n",
        "    raise ValueError('Missing column image_path')\n",
        "\n",
        "  # Beam needs to know the schema in advance. Can't be automatically determined\n",
        "  # since the length of the embedding is a variable. \n",
        "  metadata_fields = list(header)\n",
        "  emb_fields = ['emb_%04d' % i for i in range(EMB_LEN)]\n",
        "  schema = pyarrow.schema([(x, pyarrow.string()) for x in metadata_fields] +\n",
        "                          [(x, pyarrow.float32()) for x in emb_fields])\n",
        "  \n",
        "  p = beam.Pipeline(options=options)\n",
        "  beam_df = p | beam.dataframe.io.read_csv(\n",
        "      image_metadata_path, dtype=str)\n",
        "  p_metadata = (beam.dataframe.convert.to_pcollection(beam_df) |\n",
        "                'row_to_dict' \u003e\u003e beam.Map(lambda x: dict(x._asdict())) |\n",
        "                'Reshuffle1' \u003e\u003e beam.Reshuffle())\n",
        "  p_image = p_metadata | beam.Map(load_img)\n",
        "  p_emb = p_image | 'compute_embeddings' \u003e\u003e beam.ParDo(Embedder())\n",
        "  p_rows = p_emb | beam.Map(to_row, metadata_fields, emb_fields)\n",
        "  p_rows |= 'Resuffle2' \u003e\u003e beam.Reshuffle()\n",
        "  _ = p_rows | beam.io.parquetio.WriteToParquet(output_path,\n",
        "                                                schema,\n",
        "                                                num_shards=num_output_shards)\n",
        "\n",
        "  return p\n",
        "\n",
        "def run_pipeline(image_metadata_path,\n",
        "                 output_path,\n",
        "                 num_output_shards=None,\n",
        "                 options=None):\n",
        "  pipeline = make_pipeline(image_metadata_path,\n",
        "                           output_path,\n",
        "                           num_output_shards=num_output_shards,\n",
        "                           options=options)\n",
        "  pipeline_result = pipeline.run()\n",
        "  if hasattr(pipeline_result, '_job'):\n",
        "    # It was launched on cloud dataflow. Print the URL for the job.\n",
        "    url = ('https://console.cloud.google.com/dataflow/jobs/%s/%s?project=%s' % \n",
        "          (pipeline_result._job.location,\n",
        "          pipeline_result._job.id,\n",
        "          pipeline_result._job.projectId))\n",
        "    print(url)\n",
        "  return pipeline_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unhE-l3pVnp3"
      },
      "source": [
        "**Do a local test run**\n",
        "\n",
        "The pipeline expects one grayscale image per stain. The paths to these images and any associated labels are given in a csv file.\n",
        "\n",
        "Create an example csv file and example images to do a test run of the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "executionInfo": {
          "elapsed": 107,
          "status": "ok",
          "timestamp": 1652915943710,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "wyRxUlwbVmfw",
        "outputId": "78ce939e-0cca-487a-ad20-f9bd574d6c43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing example_image_metadata.csv\n"
          ]
        }
      ],
      "source": [
        "%%writefile example_image_metadata.csv\n",
        "image_path,batch,plate,well,site,stain\n",
        "im1.tiff,batch_01,plate_02,A05,42,DAPI\n",
        "im2.tiff,batch_01,plate_02,A05,42,RNA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "executionInfo": {
          "elapsed": 106,
          "status": "ok",
          "timestamp": 1652915945554,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "eB7n8_NpWNYo",
        "outputId": "ec7b37ea-c0a1-4870-f0ea-6bbf13e801aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote to im1.tiff\n",
            "Wrote to im2.tiff\n"
          ]
        }
      ],
      "source": [
        "example_image_metadata_df = pd.read_csv('example_image_metadata.csv')\n",
        "\n",
        "np.random.seed(12345) # For determinism.\n",
        "\n",
        "def write_test_image(image_path):\n",
        "  array = np.random.randint(0, 65535, size=(10, 20), dtype='uint16')\n",
        "  pil_image = PilImage.fromarray(array)\n",
        "  with open(image_path, 'wb') as f:\n",
        "    pil_image.save(f, 'tiff')\n",
        "  print('Wrote to %s' % image_path)\n",
        "\n",
        "_ = example_image_metadata_df['image_path'].map(write_test_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "executionInfo": {
          "elapsed": 10258,
          "status": "ok",
          "timestamp": 1653002798767,
          "user": {
            "displayName": "Brian Williams",
            "userId": "07410353554973206216"
          },
          "user_tz": 420
        },
        "id": "kqKAXZm8qCX7",
        "outputId": "495395bb-6a5e-42e3-8c17-5ef3d7f01c14"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  \u003cdiv id=\"df-22fd3b37-eaf9-43c3-ac77-027898ba1498\"\u003e\n",
              "    \u003cdiv class=\"colab-df-container\"\u003e\n",
              "      \u003cdiv\u003e\n",
              "\u003cstyle scoped\u003e\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\u003c/style\u003e\n",
              "\u003ctable border=\"1\" class=\"dataframe\"\u003e\n",
              "  \u003cthead\u003e\n",
              "    \u003ctr style=\"text-align: right;\"\u003e\n",
              "      \u003cth\u003e\u003c/th\u003e\n",
              "      \u003cth\u003eimage_path\u003c/th\u003e\n",
              "      \u003cth\u003ebatch\u003c/th\u003e\n",
              "      \u003cth\u003eplate\u003c/th\u003e\n",
              "      \u003cth\u003ewell\u003c/th\u003e\n",
              "      \u003cth\u003esite\u003c/th\u003e\n",
              "      \u003cth\u003estain\u003c/th\u003e\n",
              "      \u003cth\u003eemb_0000\u003c/th\u003e\n",
              "      \u003cth\u003eemb_0001\u003c/th\u003e\n",
              "      \u003cth\u003eemb_0002\u003c/th\u003e\n",
              "      \u003cth\u003eemb_0003\u003c/th\u003e\n",
              "      \u003cth\u003e...\u003c/th\u003e\n",
              "      \u003cth\u003eemb_2038\u003c/th\u003e\n",
              "      \u003cth\u003eemb_2039\u003c/th\u003e\n",
              "      \u003cth\u003eemb_2040\u003c/th\u003e\n",
              "      \u003cth\u003eemb_2041\u003c/th\u003e\n",
              "      \u003cth\u003eemb_2042\u003c/th\u003e\n",
              "      \u003cth\u003eemb_2043\u003c/th\u003e\n",
              "      \u003cth\u003eemb_2044\u003c/th\u003e\n",
              "      \u003cth\u003eemb_2045\u003c/th\u003e\n",
              "      \u003cth\u003eemb_2046\u003c/th\u003e\n",
              "      \u003cth\u003eemb_2047\u003c/th\u003e\n",
              "    \u003c/tr\u003e\n",
              "  \u003c/thead\u003e\n",
              "  \u003ctbody\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e0\u003c/th\u003e\n",
              "      \u003ctd\u003eim1.tiff\u003c/td\u003e\n",
              "      \u003ctd\u003ebatch_01\u003c/td\u003e\n",
              "      \u003ctd\u003eplate_02\u003c/td\u003e\n",
              "      \u003ctd\u003eA05\u003c/td\u003e\n",
              "      \u003ctd\u003e42\u003c/td\u003e\n",
              "      \u003ctd\u003eDAPI\u003c/td\u003e\n",
              "      \u003ctd\u003e0.068733\u003c/td\u003e\n",
              "      \u003ctd\u003e0.345606\u003c/td\u003e\n",
              "      \u003ctd\u003e0.0\u003c/td\u003e\n",
              "      \u003ctd\u003e0.0\u003c/td\u003e\n",
              "      \u003ctd\u003e...\u003c/td\u003e\n",
              "      \u003ctd\u003e0.710415\u003c/td\u003e\n",
              "      \u003ctd\u003e0.141535\u003c/td\u003e\n",
              "      \u003ctd\u003e0.000000\u003c/td\u003e\n",
              "      \u003ctd\u003e0.001137\u003c/td\u003e\n",
              "      \u003ctd\u003e0.0\u003c/td\u003e\n",
              "      \u003ctd\u003e0.0\u003c/td\u003e\n",
              "      \u003ctd\u003e0.0\u003c/td\u003e\n",
              "      \u003ctd\u003e0.151024\u003c/td\u003e\n",
              "      \u003ctd\u003e0.0\u003c/td\u003e\n",
              "      \u003ctd\u003e0.029063\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e1\u003c/th\u003e\n",
              "      \u003ctd\u003eim2.tiff\u003c/td\u003e\n",
              "      \u003ctd\u003ebatch_01\u003c/td\u003e\n",
              "      \u003ctd\u003eplate_02\u003c/td\u003e\n",
              "      \u003ctd\u003eA05\u003c/td\u003e\n",
              "      \u003ctd\u003e42\u003c/td\u003e\n",
              "      \u003ctd\u003eRNA\u003c/td\u003e\n",
              "      \u003ctd\u003e0.044517\u003c/td\u003e\n",
              "      \u003ctd\u003e1.047723\u003c/td\u003e\n",
              "      \u003ctd\u003e0.0\u003c/td\u003e\n",
              "      \u003ctd\u003e0.0\u003c/td\u003e\n",
              "      \u003ctd\u003e...\u003c/td\u003e\n",
              "      \u003ctd\u003e0.884657\u003c/td\u003e\n",
              "      \u003ctd\u003e0.460547\u003c/td\u003e\n",
              "      \u003ctd\u003e0.065838\u003c/td\u003e\n",
              "      \u003ctd\u003e0.005723\u003c/td\u003e\n",
              "      \u003ctd\u003e0.0\u003c/td\u003e\n",
              "      \u003ctd\u003e0.0\u003c/td\u003e\n",
              "      \u003ctd\u003e0.0\u003c/td\u003e\n",
              "      \u003ctd\u003e0.000000\u003c/td\u003e\n",
              "      \u003ctd\u003e0.0\u003c/td\u003e\n",
              "      \u003ctd\u003e0.000000\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "  \u003c/tbody\u003e\n",
              "\u003c/table\u003e\n",
              "\u003cp\u003e2 rows × 2054 columns\u003c/p\u003e\n",
              "\u003c/div\u003e\n",
              "      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22fd3b37-eaf9-43c3-ac77-027898ba1498')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\"\u003e\n",
              "        \n",
              "  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\"\u003e\n",
              "    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n",
              "    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n",
              "  \u003c/svg\u003e\n",
              "      \u003c/button\u003e\n",
              "      \n",
              "  \u003cstyle\u003e\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  \u003c/style\u003e\n",
              "\n",
              "      \u003cscript\u003e\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-22fd3b37-eaf9-43c3-ac77-027898ba1498 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-22fd3b37-eaf9-43c3-ac77-027898ba1498');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      \u003c/script\u003e\n",
              "    \u003c/div\u003e\n",
              "  \u003c/div\u003e\n",
              "  "
            ],
            "text/plain": [
              "  image_path     batch     plate well site stain  emb_0000  emb_0001  \\\n",
              "0   im1.tiff  batch_01  plate_02  A05   42  DAPI  0.068733  0.345606   \n",
              "1   im2.tiff  batch_01  plate_02  A05   42   RNA  0.044517  1.047723   \n",
              "\n",
              "   emb_0002  emb_0003  ...  emb_2038  emb_2039  emb_2040  emb_2041  emb_2042  \\\n",
              "0       0.0       0.0  ...  0.710415  0.141535  0.000000  0.001137       0.0   \n",
              "1       0.0       0.0  ...  0.884657  0.460547  0.065838  0.005723       0.0   \n",
              "\n",
              "   emb_2043  emb_2044  emb_2045  emb_2046  emb_2047  \n",
              "0       0.0       0.0  0.151024       0.0  0.029063  \n",
              "1       0.0       0.0  0.000000       0.0  0.000000  \n",
              "\n",
              "[2 rows x 2054 columns]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_pipeline('example_image_metadata.csv', 'example_outfile')\n",
        "\n",
        "pd.read_parquet('example_outfile-00000-of-00001')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miz1J-XjX-gM"
      },
      "source": [
        "**Launch on Cloud Dataflow**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXuzH7MFvrG8"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8DoyZXF0giDI"
      },
      "outputs": [],
      "source": [
        "GCS_PROJECT = 'YOUR_PROJECT' # @param { type: \"string\", isTemplate: true}\n",
        "GCS_BUCKET = 'YOUR_BUCKET' # @param { type: \"string\", isTemplate: true}\n",
        "GCS_REGION = 'YOUR_REGION' # @param { type: \"string\", isTemplate: true}\n",
        "GCS_ROOT_DIR = 'gs://YOUR_BUCKET/test_embedding/' # @param { type: \"string\", isTemplate: true}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Cgtj7AZijDJ"
      },
      "outputs": [],
      "source": [
        "# Copy example input data to cloud.\n",
        "gcs_example_image_metadata_df = example_image_metadata_df.copy()\n",
        "gcs_example_image_metadata_df['image_path'] = (GCS_ROOT_DIR + gcs_example_image_metadata_df['image_path'])\n",
        "gcs_example_image_metadata_df.to_csv('gcs_example_image_metadata.csv', index=False)\n",
        "gcs_image_metadata_path = os.path.join(GCS_ROOT_DIR, 'example_image_metadata.csv')\n",
        "\n",
        "!gsutil cp gcs_example_image_metadata.csv {gcs_image_metadata_path}\n",
        "!gsutil cp im1.tiff {GCS_ROOT_DIR}im1.tiff\n",
        "!gsutil cp im2.tiff {GCS_ROOT_DIR}im2.tiff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDd4Xv3lijDK"
      },
      "outputs": [],
      "source": [
        "%%writefile requirements.txt\n",
        "apache-beam[gcp,dataframe]\u003e=2.38.0\n",
        "fsspec[gcs]\u003e=2022.3.0\n",
        "numpy\u003e=1.21.6\n",
        "pandas\u003e=1.3.5\n",
        "Pillow\u003e=9.1.0\n",
        "tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJ5WzCF5ijDK"
      },
      "outputs": [],
      "source": [
        "def get_pipeline_options(project, bucket, region):\n",
        "  \"\"\"Returns cloud dataflow pipeline options.\"\"\"\n",
        "  options = pipeline_options.PipelineOptions(flags=[\n",
        "      '--requirements_file',\n",
        "      'requirements.txt',\n",
        "      '--runner',\n",
        "      'DataflowRunner',\n",
        "      # Flag use_runner_v2 avoids a segfault when worker pool starts.\n",
        "      # Probably not needed long term.\n",
        "      '--experiments',\n",
        "      'use_runner_v2'\n",
        "  ])\n",
        "  options.view_as(pipeline_options.GoogleCloudOptions).project = project\n",
        "  options.view_as(pipeline_options.GoogleCloudOptions).region = region\n",
        "  dataflow_gcs_location = 'gs://%s/dataflow' % bucket\n",
        "  options.view_as(pipeline_options.GoogleCloudOptions\n",
        "                 ).staging_location = '%s/staging' % dataflow_gcs_location\n",
        "  options.view_as(pipeline_options.GoogleCloudOptions\n",
        "                 ).temp_location = '%s/temp' % dataflow_gcs_location\n",
        "  return options\n",
        "\n",
        "options = get_pipeline_options(GCS_PROJECT, GCS_BUCKET, GCS_REGION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXK6a5iJijDL"
      },
      "outputs": [],
      "source": [
        "gcs_output_path = os.path.join(GCS_ROOT_DIR, 'output')\n",
        "num_output_shards = 1 # Increase for larger datasets.\n",
        "\n",
        "result = run_pipeline(gcs_image_metadata_path,\n",
        "                      gcs_output_path,\n",
        "                      num_output_shards=num_output_shards,\n",
        "                      options=options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpjD3YAdijDL"
      },
      "outputs": [],
      "source": [
        "# Open the result when the pipeline is done.\n",
        "first_shard_path = gcs_output_path + ('-00000-of-%05d' % num_output_shards)\n",
        "with fsspec.open(first_shard_path) as f:\n",
        "  df = pd.read_parquet(f)\n",
        "df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "//research/biology/diagnose_a_well:daw_fpi_notebook",
        "kind": "shared"
      },
      "name": "make_embeddings.ipynb",
      "provenance": [
        {
          "file_id": "15I9yddQHYsj3mIysslsvOBT0T44XcIpX",
          "timestamp": 1652745751597
        },
        {
          "file_id": "1bhhpkPYgJzOwj86GTl59MQTLh97_JXGQ",
          "timestamp": 1652584572323
        },
        {
          "file_id": "1nhNKdxWhUMjyYKjvgUI_uKk2UkVJAaRC",
          "timestamp": 1652544177295
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
