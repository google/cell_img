{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCg2twtm6QRJ"
      },
      "source": [
        "This Colab estimates inhibition based on both counts and appearance (i.e. Joint Inhibition) for:\n",
        "* hypnozoites\n",
        "* parasites\n",
        "\n",
        "The input dataset is designed to be a set of screening plates, though the joint inhibition can be calculated for dose response or other types of plates also."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDJQ_-bd0OiD"
      },
      "outputs": [],
      "source": [
        "#@title Run this cell only the FIRST time you connect to the colab kernel\n",
        "!pip install gcsfs\n",
        "!git clone https://github.com/google/cell_img\n",
        "!pip install --quiet -e cell_img\n",
        "!pip install jax\n",
        "!pip install lightgbm\n",
        "!pip install optax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiMmjrcxcCxY"
      },
      "outputs": [],
      "source": [
        "#@title For Cloud VM kernel, run this after restarting before granting access\n",
        "\n",
        "!ls /content/.config/\n",
        "!rm /content/.config/gce \n",
        "!rm /var/colab/mp\n",
        "\n",
        "import os\n",
        "os.environ['NO_GCE_CHECK']\n",
        "del os.environ['NO_GCE_CHECK']\n",
        "os.environ['GCE_METADATA_TIMEOUT']\n",
        "del os.environ['GCE_METADATA_TIMEOUT']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqBoOaYi0OiE"
      },
      "outputs": [],
      "source": [
        "#@title Run this cell after restarting your kernel. It will pop up window to grant access.\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MT75blFWGJAj"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ke4Vlu2eK5JI"
      },
      "outputs": [],
      "source": [
        "#@title Choose type of inhibition to estimate\n",
        "INHIBITION_TYPE = 'hypnozoite'  #@param ['hypnozoite', 'parasite'] {allow-input: true}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pviiSLjlLHTb"
      },
      "outputs": [],
      "source": [
        "print(INHIBITION_TYPE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrHNVt9YM5j0"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import datetime\n",
        "import dataclasses\n",
        "import fsspec\n",
        "import gc\n",
        "import os\n",
        "import pathlib\n",
        "import re\n",
        "from google.cloud import storage\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import optax\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "import scipy.stats\n",
        "import seaborn as sns\n",
        "import sklearn.metrics\n",
        "import cycler\n",
        "import matplotlib\n",
        "\n",
        "import lightgbm\n",
        "\n",
        "import statsmodels.nonparametric.smoothers_lowess\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import cell_img\n",
        "from cell_img.analysis import jax_tree\n",
        "from cell_img.common import image_lib\n",
        "from cell_img.dose_response import constrain\n",
        "from cell_img.predict_inhibition import joint_model\n",
        "from cell_img.predict_inhibition import spline\n",
        "from cell_img.malaria_liver import metadata_lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OMYEim5tSJl"
      },
      "outputs": [],
      "source": [
        "# Set up matplotlib styles\n",
        "matplotlib.rcParams['axes.prop_cycle'] = cycler.cycler(\n",
        "    'color', matplotlib.cm.get_cmap('tab10').colors)\n",
        "\n",
        "IMAGE_STYLE = {\n",
        "    'axes.grid': False,\n",
        "    'axes.linewidth': 0,\n",
        "\n",
        "    'xtick.labelsize': 0,\n",
        "    'xtick.color': 'none',\n",
        "    'xtick.major.size': 0,\n",
        "    'xtick.minor.size': 0,\n",
        "\n",
        "    'ytick.labelsize': 0,\n",
        "    'ytick.color': 'none',\n",
        "    'ytick.major.size': 0,\n",
        "    'ytick.minor.size': 0,\n",
        "\n",
        "    'image.cmap': 'viridis',\n",
        "    'image.interpolation': 'none',\n",
        "\n",
        "    'figure.subplot.hspace': 0.02,\n",
        "    'figure.subplot.wspace': 0.04,\n",
        "\n",
        "    'figure.subplot.left': 0.01,\n",
        "    'figure.subplot.bottom': 0.01,\n",
        "    'figure.subplot.right': 0.98,\n",
        "    'figure.subplot.top': 0.98,\n",
        "    'font.size': 22,\n",
        "}\n",
        "\n",
        "COLORS = plt.cm.tab10(np.linspace(0, 1, 10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYV-_dbgbx9S"
      },
      "outputs": [],
      "source": [
        "assert INHIBITION_TYPE in {'parasite', 'hypnozoite'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dT7XkDNm7XN4"
      },
      "outputs": [],
      "source": [
        "# filtered count data and embeddings as generated by prepare_data.ipynb\n",
        "\n",
        "CLOUD_BUCKET = 'bucket'\n",
        "\n",
        "PREDICT_INHIBITION_PATH = 'your/path/'\n",
        "\n",
        "# parasite embeddings\n",
        "batches = [ 'batch1', 'batch2' ]\n",
        "files_to_load = [\n",
        "    f'{PREDICT_INHIBITION_PATH}prefix_{batch}.parquet'\n",
        "    for batch in batches]\n",
        "\n",
        "\n",
        "# count data\n",
        "DF_DATE = 'date-count-data-generated'\n",
        "COUNT_DF_PATH = os.path.join(\n",
        "    f'gs://{CLOUD_BUCKET}', PREDICT_INHIBITION_PATH,\n",
        "    f'count_df-{DF_DATE}.parquet')\n",
        "\n",
        "# output file\n",
        "today_str = datetime.date.today().isoformat()\n",
        "INHIBITION_FILE = os.path.join(\n",
        "    f'gs://{CLOUD_BUCKET}', PREDICT_INHIBITION_PATH,\n",
        "    f'joint_inhibition_{INHIBITION_TYPE}-{today_str}.parquet')\n",
        "\n",
        "# dose-response estimates\n",
        "DOSE_RESPONSE_PATH = f'gs://{CLOUD_BUCKET}/path/to/dose_response'\n",
        "DOSE_RESPONSE_FILE = os.path.join(DOSE_RESPONSE_PATH, f'dr_df.parquet')\n",
        "\n",
        "# TensorStore parameters for patch images\n",
        "TENSORSTORE_SHORTNAME = 'short_name'\n",
        "TENSORSTORE_PATH = f'gs://{CLOUD_BUCKET}/tensorstore/{TENSORSTORE_SHORTNAME}'\n",
        "METADATA_ROOT_PATH = f'gs://{CLOUD_BUCKET}/tensorstore/{TENSORSTORE_SHORTNAME}/metadata/'\n",
        "CHANNEL_TO_RGB = ['w3', 'w2', 'w1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26A08aRHnN_O"
      },
      "outputs": [],
      "source": [
        "def pd_read_parquet(path, filter_list):\n",
        "  with fsspec.open(path) as f:\n",
        "    if filter_list:\n",
        "      return pd.read_parquet(f, filters=filter_list)\n",
        "    else:\n",
        "      return pd.read_parquet(f)\n",
        "\n",
        "\n",
        "def compress_df(df: pd.DataFrame) -\u003e pd.DataFrame:\n",
        "  \"\"\"Reduce the byte size of columns.\"\"\"\n",
        "  for col in df.columns:\n",
        "    if df[col].dtype == np.float64:\n",
        "      df[col] = df[col].astype(np.float32)\n",
        "    elif df[col].dtype == np.int64:\n",
        "      df[col] = df[col].astype(np.int32)\n",
        "  return df\n",
        "\n",
        "\n",
        "def format_plate_strings(plate_names):\n",
        "  \"\"\"Format the plate strings as strings of five digit ints.\n",
        "\n",
        "  Args:\n",
        "    plate_names: A pd.Series of strings representing the plate names that we\n",
        "      want to format.\n",
        "  Raises:\n",
        "    ValueError: If plate_names contains a name that is more than five digits\n",
        "      long.\n",
        "  Returns:\n",
        "    formatted_plates: A pd.Series representing the formatted plate names.\n",
        "  \"\"\"\n",
        "  # Format the plate strings as 5 character strings with no decimal\n",
        "  formatted_plates = plate_names.astype(str).apply(\n",
        "      lambda x: x.split('.')[0].zfill(5))\n",
        "  # If any of the plates are more than 5 digits, scream loudly.\n",
        "  len_plate_names = np.array([len(p) for p in formatted_plates.values])\n",
        "  if np.any(len_plate_names \u003e 5):\n",
        "    raise ValueError('Plate name \u003e 5 characters found')\n",
        "  # If any of the plates have non-digit characters, scream loudly.\n",
        "  if not np.all([re.match(r'^\\d+$', p) for p in formatted_plates.values]):\n",
        "    raise ValueError('Plate with non-digit characters found')\n",
        "  return formatted_plates\n",
        "\n",
        "\n",
        "def glob_cloud(bucket, path):\n",
        "  client = storage.Client()\n",
        "  return [blob.name for blob in client.list_blobs(bucket, prefix=path)]\n",
        "  emb_df = compress_df(pd_read_parquet(parquet_filename, filter_list))\n",
        "\n",
        "\n",
        "def load_subset_dataset_to_emb_df(files_to_load,\n",
        "                                  expand_embedding=True, filter_list=None):\n",
        "  # Read the new Parquet output\n",
        "  emb_df_list = []\n",
        "  num_files_loaded = 0\n",
        "  for f in files_to_load:\n",
        "    num_files_loaded += 1\n",
        "    f_to_load = os.path.join(f'gs://{CLOUD_BUCKET}', f)\n",
        "    one_df = pd_read_parquet(f_to_load, filter_list)\n",
        "    # expand the embedding\n",
        "    if expand_embedding:\n",
        "      tmp_df = pd.DataFrame([pd.Series(x) for x in one_df.embedding])\n",
        "      tmp_df.columns = [str(x) for x in range(192)]\n",
        "      one_df = pd.concat([one_df.reset_index(), tmp_df], axis=1)\n",
        "      one_df.drop(columns=['embedding'], inplace=True)\n",
        "    emb_df_list.append(compress_df(one_df))\n",
        "  emb_df = pd.concat(emb_df_list)\n",
        "\n",
        "  print('Loaded %d rows across %d batches in %d files!' % (\n",
        "      len(emb_df), emb_df.batch.nunique(), num_files_loaded\n",
        "  ))\n",
        "\n",
        "  return emb_df.rename(columns={str(i): i for i in range(192)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAyWeMx__MD2"
      },
      "outputs": [],
      "source": [
        "# Note: takes 6-7 minutes to run\n",
        "patch_df = load_subset_dataset_to_emb_df(files_to_load)\n",
        "patch_df.set_index('index', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tecYgSNCyt7"
      },
      "outputs": [],
      "source": [
        "# constants for variable names, embedding dimensions, and whether to weight data\n",
        "if INHIBITION_TYPE == 'hypnozoite':\n",
        "  # embedding columns we use\n",
        "  COUNT_COL = 'ml_hypnozoite'\n",
        "  INHIBITION_COL = 'inhibition_ml_hyp'\n",
        "  EMB_COLS = list(range(64, 192))  # keep non-DAPI stains\n",
        "  WEIGHT_SAMPLES = True\n",
        "\n",
        "elif INHIBITION_TYPE == 'parasite':\n",
        "  # embedding columns we use\n",
        "  COUNT_COL = 'ml_parasite'\n",
        "  INHIBITION_COL = 'inhibition_ml_par'\n",
        "  EMB_COLS = list(range(64, 192))  # keep non-DAPI stains\n",
        "  WEIGHT_SAMPLES = True\n",
        "\n",
        "else:\n",
        "  raise ValueError('Invalid INHIBITION_TYPE %s' % INHIBITION_TYPE)\n",
        "\n",
        "EMB_DIM = len(EMB_COLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPlQSD-JKnNM"
      },
      "outputs": [],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ib8QEMUhuqKp"
      },
      "source": [
        "## Step 1: predict hypnozoite inhibition in a well given a single parasite image\n",
        "\n",
        "We build a regression model that predicts well-level inhibition from individual parasite embeddings. This is going to be weak predictor, but we will later show that it can be improved by (1) combining predictions from multiple parasites in a well, and (2) by combining parasite appearance with parasite counts.\n",
        "\n",
        "We use LightGBM to generate our predictions. Our primary input features are embeddings for parasite-specific stains (i.e. no DAPI). There is considerable variation in the embeddings from plate to plate and batch to batch, so we tried\n",
        "a few different approaches to controlling for it.\n",
        "\n",
        "The biggest source of variation appears to be the hepatocyte lot in which the\n",
        "parasites were cultivated. One straightforward way to control for the effects of hep lot on appearance is to include hep lot as a categorical predictor. We found that while including hep lot improved the model's predictions, it led to difficulties later when we combine appearance and count-based measures of inhibition. An alternative approach that we found helpful was to combine an\n",
        "embedding for a treated hypnozoite with an embedding for an untreated control hypnozoite from the same plate. We use the latter approach below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3RmbqB6zOtB"
      },
      "outputs": [],
      "source": [
        "# Split data into training, validation, and test subsets for model training\n",
        "# and evaluation. We'll split by plate.\n",
        "\n",
        "np.random.seed(123)\n",
        "\n",
        "DATA_FRACTION = 1.\n",
        "\n",
        "fraction_train = 0.8\n",
        "fraction_validation = 0.1\n",
        "fraction_test = 1. - fraction_train - fraction_validation\n",
        "\n",
        "plates = sorted(set(patch_df.plate))\n",
        "n_plates = len(plates)\n",
        "perm = np.random.permutation(n_plates)\n",
        "\n",
        "train_plates = {plates[i] for i in perm[:int(fraction_train * n_plates)]}\n",
        "validation_plates = {plates[i] for i in perm[int(fraction_train * n_plates):int((1. - fraction_test) * n_plates)]}\n",
        "test_plates = {plates[i] for i in perm[int((1. - fraction_test) * n_plates):]}\n",
        "\n",
        "# sanity check - make sure there's no overlap between the sets of plates\n",
        "print('n_train', len(train_plates),\n",
        "      'overlap', len(train_plates \u0026 validation_plates), len(train_plates \u0026 test_plates))\n",
        "print('n_validation', len(validation_plates),\n",
        "      'overlap', len(validation_plates \u0026 test_plates))\n",
        "print('n_test', len(test_plates))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-dxYdSwXD-5"
      },
      "outputs": [],
      "source": [
        "# clipped logit function that bounds output to MIN_LOGIT, MAX_LOGIT\n",
        "MIN_P = scipy.special.expit(joint_model.MIN_LOGIT_INHIBITION)\n",
        "MAX_P = scipy.special.expit(joint_model.MAX_LOGIT_INHIBITION)\n",
        "\n",
        "def clipped_logit(x: np.array) -\u003e np.array:\n",
        "  return scipy.special.logit(np.clip(x, MIN_P, MAX_P))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mi6AKTsKgpQC"
      },
      "outputs": [],
      "source": [
        "# Get features and objective for LightGBM\n",
        "def get_xy(df: pd.DataFrame,\n",
        "           use_infected_controls: bool,\n",
        "           use_active_controls: bool,\n",
        "           use_hep_lot: bool):\n",
        "  \"\"\"Get x, y, and weights for model training.\"\"\"\n",
        "  features_df = []\n",
        "  for plate, plate_df in df[df.actives != 'uninfected_control'].groupby(['plate']):\n",
        "\n",
        "    n = plate_df.shape[0]\n",
        "    # the first set of features is the embedding vector for a parasite\n",
        "    features = [plate_df[EMB_COLS].to_numpy().astype(np.float32)]\n",
        "\n",
        "    if use_infected_controls:\n",
        "      # Optional: we want to measure how stressed treated parasites are *relative to untreated parasites*\n",
        "      # One way to get at this is to add a random untreated (infected_control) parasite from the same plate\n",
        "      # for contrast\n",
        "      infected_controls = plate_df[plate_df.actives == 'infected_control'][EMB_COLS].to_numpy().astype(np.float32)\n",
        "      n_infected_control = infected_controls.shape[0]\n",
        "      features.append(infected_controls[np.random.choice(n_infected_control, size=n, replace=True)])\n",
        "\n",
        "    if use_active_controls:\n",
        "      # Optional: another point of reference for how damaged parasites look is how parasites treated with\n",
        "      # active controls on the same plate look. Here we add a random active_control parasite for contrast.\n",
        "      active_controls = plate_df[plate_df.actives == 'active_control'][EMB_COLS].to_numpy().astype(np.float32)\n",
        "      n_active_control = active_controls.shape[0]\n",
        "      features.append(active_controls[np.random.choice(n_active_control, size=n, replace=True)])\n",
        "\n",
        "    plate_features_df = pd.DataFrame(np.column_stack(features), index=plate_df.index)\n",
        "    if use_hep_lot:\n",
        "      # Optional: Hepatocyte lot can make a big difference to parasite embeddings. One way to correct for\n",
        "      # hep lot effects is to add the hep lot as a covariate. Note that this feature needs to be treated\n",
        "      # as a categorical variable (which we do below).\n",
        "      plate_features_df['hep_lot_index'] = plate_df.hep_lot_index\n",
        "    plate_features_df['y'] = clipped_logit(plate_df[INHIBITION_COL])\n",
        "    if WEIGHT_SAMPLES:\n",
        "      # Wells with low inhibition are overrepresented in the data because they\n",
        "      # have more parasites. We weight by 1/(1-inhibition) to compensate.\n",
        "      # For example, parasites from a well with 0% inhibition have weight 1,\n",
        "      # parasites from a well with 50% inhibition have weight 2 (since there are\n",
        "      # half as many of them), etc.\n",
        "      plate_features_df['weight'] = 1. / (1. - plate_df[INHIBITION_COL])\n",
        "    else:\n",
        "      plate_features_df['weight'] = 1.\n",
        "\n",
        "    features_df.append(plate_features_df)\n",
        "\n",
        "  return pd.concat(features_df, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWdlPkxYzrMc"
      },
      "outputs": [],
      "source": [
        "# Get training, validation, and test data sets for LightGBM\n",
        "np.random.seed(123)\n",
        "\n",
        "USE_INFECTED_CONTROLS = True\n",
        "USE_ACTIVE_CONTROLS = False\n",
        "USE_HEP_LOT = False\n",
        "\n",
        "# We're pairing each treated parasite with a random\n",
        "# infected control and active control, then making\n",
        "# a prediction. Here we'll take N_PREDICTIONS predictions,\n",
        "# each with a different random infected / active control,\n",
        "# and average them\n",
        "N_PREDICTIONS = 4\n",
        "\n",
        "FEATURE_COLS = list(range(EMB_DIM * (1 + int(USE_INFECTED_CONTROLS) + int(USE_ACTIVE_CONTROLS))))\n",
        "if USE_HEP_LOT:\n",
        "  FEATURE_COLS += ['hep_lot_index']\n",
        "\n",
        "train_df = get_xy(\n",
        "    patch_df[patch_df.plate.isin(train_plates)],\n",
        "    use_infected_controls=USE_INFECTED_CONTROLS,\n",
        "    use_active_controls=USE_ACTIVE_CONTROLS,\n",
        "    use_hep_lot=USE_HEP_LOT,)\n",
        "\n",
        "validation_df = get_xy(\n",
        "    patch_df[patch_df.plate.isin(validation_plates)],\n",
        "    use_infected_controls=USE_INFECTED_CONTROLS,\n",
        "    use_active_controls=USE_ACTIVE_CONTROLS,\n",
        "    use_hep_lot=USE_HEP_LOT,)\n",
        "\n",
        "test_df = get_xy(\n",
        "    patch_df[patch_df.plate.isin(test_plates)],\n",
        "    use_infected_controls=USE_INFECTED_CONTROLS,\n",
        "    use_active_controls=USE_ACTIVE_CONTROLS,\n",
        "    use_hep_lot=USE_HEP_LOT,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKOftcne-Jz7"
      },
      "outputs": [],
      "source": [
        "# make sure the train_df has all hep lots\n",
        "if USE_HEP_LOT:\n",
        "  print(set(train_df['hep_lot_index']), set(validation_df['hep_lot_index']), set(test_df['hep_lot_index']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkOD6WtrZl2a"
      },
      "outputs": [],
      "source": [
        "train_df.shape, validation_df.shape, test_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3n2Jp_P6USlv"
      },
      "outputs": [],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18BijJ-bwyMw"
      },
      "outputs": [],
      "source": [
        "# Predict inhibition from individual parasites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXvrsMY8jNvu"
      },
      "outputs": [],
      "source": [
        "n_estimators = 1000\n",
        "lgbm_inhibition = lightgbm.LGBMRegressor(\n",
        "    n_estimators=n_estimators,  # controls the maximum size of the model\n",
        "    boosting='goss',\n",
        "\n",
        "    # Regularization\n",
        "    max_depth=2,  # this is probably the strongest constraint\n",
        "    min_data_in_leaf=1000,  # default is 20\n",
        "    lambda_l1=10.,\n",
        "    lambda_l2=10.,\n",
        "\n",
        "    # Miscellaneous\n",
        "    feature_fraction=1.,  # Setting smaller fractions reduces training time but worsens results\n",
        "    learning_rate=0.1,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gei_7ehxOxNi"
      },
      "outputs": [],
      "source": [
        "# Fit the model\n",
        "kwargs = {}\n",
        "if USE_HEP_LOT:\n",
        "  kwargs['categorical_feature'] = ['hep_lot_index']\n",
        "\n",
        "lgbm_inhibition.fit(\n",
        "    train_df[FEATURE_COLS],\n",
        "    train_df['y'],\n",
        "    sample_weight=train_df['weight'],\n",
        "    eval_set=[(validation_df[FEATURE_COLS],\n",
        "               validation_df['y'])],\n",
        "    eval_sample_weight=[validation_df['weight']],\n",
        "    early_stopping_rounds=n_estimators // 10,\n",
        "    **kwargs,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNVDBCh3tf0I"
      },
      "outputs": [],
      "source": [
        "if INHIBITION_TYPE in {'hypnozoite', 'parasite'}:\n",
        "  # in general stain #3 looks a little more important than stain #2 (we've dropped DAPI, stain #1)\n",
        "  # the model puts considerably more weight on the treated parasite than the paired control parasite\n",
        "  print('sample')\n",
        "  print('stain 2', np.mean(lgbm_inhibition.feature_importances_[:64]))\n",
        "  print('stain 3', np.mean(lgbm_inhibition.feature_importances_[64:128]))\n",
        "\n",
        "  print('infected control')\n",
        "  print('stain 2', np.mean(lgbm_inhibition.feature_importances_[128:192]))\n",
        "  print('stain 3', np.mean(lgbm_inhibition.feature_importances_[192:256]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkEIIyIWrwPw"
      },
      "outputs": [],
      "source": [
        "if USE_INFECTED_CONTROLS:\n",
        "  # See if the classifier uses the same features for the samples ([:EMB_DIM])\n",
        "  # and the infected controls ([EMB_DIM:2*EMB_DIM])\n",
        "  # (Not really!)\n",
        "  print(\n",
        "      np.corrcoef(\n",
        "          lgbm_inhibition.feature_importances_[:EMB_DIM],\n",
        "          lgbm_inhibition.feature_importances_[EMB_DIM:2*EMB_DIM])[0, 1]\n",
        "  )\n",
        "  plt.scatter(lgbm_inhibition.feature_importances_[:EMB_DIM],\n",
        "              lgbm_inhibition.feature_importances_[EMB_DIM:2*EMB_DIM])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFzxr5AehpiA"
      },
      "outputs": [],
      "source": [
        "# Compare the train and test mean squared error - they look comparable\n",
        "y_pred_train = lgbm_inhibition.predict(train_df[FEATURE_COLS])\n",
        "mse_train = np.mean((train_df['y'] - y_pred_train)**2)\n",
        "print('Train MSE', mse_train)\n",
        "\n",
        "y_pred_test = lgbm_inhibition.predict(test_df[FEATURE_COLS])\n",
        "mse_test = np.mean((test_df['y'] - y_pred_test)**2)\n",
        "print('Test MSE', mse_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTaj13g23kLl"
      },
      "outputs": [],
      "source": [
        "del train_df, validation_df, test_df, y_pred_train, y_pred_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyJ8zqk7N0cV"
      },
      "outputs": [],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV1M8NypGV8u"
      },
      "source": [
        "### Generate predicted inhibition estimates for the whole dataset\n",
        "\n",
        "We paired each treated parasite with a random untreated parasite to help the model control for plate-to-plate variations in appearance. The randomness in the paired control hypnozoite introduces some noise into our estimates. Now we'll average over several random pairings to try to reduce that noise. (We found that this step didn't make a huge difference.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubx_ISR5hrDY"
      },
      "outputs": [],
      "source": [
        "# The model uses a treated parasite plus a random infected control and/or active control parasite as features.\n",
        "# Make N_PREDICTIONS, each of which uses different paired control parasites and then average the predictions.\n",
        "\n",
        "def _make_predictions(patch_df):\n",
        "  prediction_df = None\n",
        "  cols = []\n",
        "  for seed in range(N_PREDICTIONS):\n",
        "    col = f'pred_inhibition_logit_{seed}'\n",
        "    cols.append(col)\n",
        "    np.random.seed(seed)\n",
        "    print(seed, flush=True)\n",
        "    feature_df = get_xy(\n",
        "      patch_df,\n",
        "      use_infected_controls=USE_INFECTED_CONTROLS,\n",
        "      use_active_controls=USE_ACTIVE_CONTROLS,\n",
        "      use_hep_lot=USE_HEP_LOT)\n",
        "    df_pred = pd.DataFrame({col:\n",
        "                            lgbm_inhibition.predict(\n",
        "                                feature_df[FEATURE_COLS])},\n",
        "                          index=feature_df.index)\n",
        "\n",
        "    if prediction_df is None:\n",
        "      prediction_df = df_pred\n",
        "    else:\n",
        "      prediction_df = prediction_df.join(df_pred)\n",
        "      df_pred = None\n",
        "    del feature_df\n",
        "    gc.collect()\n",
        "  # Average the predictions\n",
        "  prediction_df['pred_inhibition_logit'] = np.mean(prediction_df[cols].to_numpy(), axis=-1)\n",
        "  prediction_df = prediction_df.drop(columns=cols)\n",
        "  return prediction_df.copy()\n",
        "\n",
        "# make predictions one batch at a time to reduce memory spikes\n",
        "prediction_df_list = []\n",
        "for b in patch_df.batch.unique():\n",
        "  print('Making predictions for %s' % b)\n",
        "  prediction_df_list.append(_make_predictions(patch_df.query(\n",
        "      'batch == \"%s\"' % b\n",
        "  )))\n",
        "prediction_df = pd.concat(prediction_df_list)\n",
        "\n",
        "prediction_df_saved = prediction_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFcZyH_rEc8N"
      },
      "outputs": [],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxjsVr6YkeBu"
      },
      "outputs": [],
      "source": [
        "prediction_df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmBUHMb7kkth"
      },
      "outputs": [],
      "source": [
        "prediction_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnLVhnozGgwq"
      },
      "source": [
        "## Appearance based predictions\n",
        "\n",
        "Here we look at some plots of our predictions.\n",
        "\n",
        "First, we plot inhibition as estimated by hypnozoite counts against our model's predictions of inhibition based on single hypnozoite appearance. Our model is quite weak - the Spearman correlation between count based inhibition estimates and appearance-based estimates is only 0.12 - but there is some signal.\n",
        "\n",
        "Note that the variance increases as the count-based inhibition increases. A reasonable interpretation is that as parasites are damaged by treatment, their appearances start to change in a wide variety of ways."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qukTS5rS94ZO"
      },
      "outputs": [],
      "source": [
        "# Look at how predictions correspond to ML inhibition for individual sample parasite embeddings.\n",
        "\n",
        "joined_df = patch_df[['actives', INHIBITION_COL]].join(prediction_df[['pred_inhibition_logit']])\n",
        "joined_df = joined_df[joined_df.actives == 'sample']\n",
        "print('Spearman correlation between ML inhibition and predictions:',\n",
        "      scipy.stats.spearmanr(joined_df[INHIBITION_COL],\n",
        "                            joined_df.pred_inhibition_logit))\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "alpha=0.1\n",
        "subset = np.random.choice(joined_df.shape[0], 50000)\n",
        "x = joined_df[INHIBITION_COL].to_numpy()[subset]\n",
        "y = joined_df.pred_inhibition_logit.to_numpy()[subset]\n",
        "sns.regplot(x=x,\n",
        "            y=y,\n",
        "            marker='.',\n",
        "            scatter_kws={'alpha': alpha},\n",
        "            line_kws={'color': 'orange'},\n",
        "            fit_reg=False,\n",
        "            )\n",
        "sub = x \u003e 0.005  # lowess has problems with big pile-up on the left\n",
        "\n",
        "lowess_mean = statsmodels.nonparametric.smoothers_lowess.lowess(y[sub], x[sub], frac=0.1, return_sorted=False)\n",
        "y_var = (y[sub] - lowess_mean) ** 2\n",
        "lowess_var = statsmodels.nonparametric.smoothers_lowess.lowess(y_var, x[sub], frac=0.1, return_sorted=False)\n",
        "idx = np.argsort(x[sub])\n",
        "\n",
        "x = x[sub][idx]\n",
        "lowess_mean = lowess_mean[idx]\n",
        "lowess_var = lowess_var[idx]\n",
        "\n",
        "x = np.concatenate([np.zeros(1), x])\n",
        "lowess_mean = np.concatenate([np.array([np.mean(y[~sub])]), lowess_mean])\n",
        "lowess_var = np.concatenate([np.array([np.var(y[~sub])]), lowess_var])\n",
        "\n",
        "plt.plot(x, lowess_mean, color='red', lw=2)\n",
        "plt.plot(x, lowess_mean + 2.*np.sqrt(lowess_var), color='red', ls='--')\n",
        "plt.plot(x, lowess_mean - 2.*np.sqrt(lowess_var), color='red', ls='--')\n",
        "plt.xlabel('Actual inhibition')\n",
        "plt.ylabel('Predicted logit inhibition')\n",
        "plt.title(f'Predicted inhibition from a single {INHIBITION_TYPE} embedding')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(x, lowess_var)\n",
        "plt.title('Variance of predictions as function of inhibition')\n",
        "plt.xlabel('Actual inhibition')\n",
        "plt.ylabel('Variance of predicted logit inhibition')\n",
        "plt.show()\n",
        "\n",
        "x_single = x\n",
        "lowess_mean_single = lowess_mean\n",
        "lowess_var_single = lowess_var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waIQnE5jImUP"
      },
      "outputs": [],
      "source": [
        "joined_df = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vg-n6xJT8ep"
      },
      "outputs": [],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcihCLcQyeNs"
      },
      "source": [
        "### Aggregating individual parasite predictions within a well\n",
        "\n",
        "Now we'll average the predicted inhibition for all hypnozoites in a well to see if we are better able to predict the count-based inhibition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RB21HpwbT3U_"
      },
      "outputs": [],
      "source": [
        "# wait to read in the count df until later to save memory\n",
        "count_df = pd.read_parquet(COUNT_DF_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sT4wUDHLJfNV"
      },
      "outputs": [],
      "source": [
        "patch_df.sample(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sm7tdEig_MX6"
      },
      "outputs": [],
      "source": [
        "# add the prediction score, counts, and inhibition to prediction_df\n",
        "prediction_df = prediction_df[['pred_inhibition_logit']].join(\n",
        "    patch_df[['batch', 'plate', 'well', 'site', 'center_row', 'center_col', 'actives', 'hep_lot', 'hep_lot_index']])\n",
        "prediction_df = prediction_df.merge(\n",
        "    count_df[['plate', 'well', COUNT_COL, INHIBITION_COL]], on=['plate', 'well'], how='left')\n",
        "prediction_df.sort_values(by=['plate', 'well', 'site', ], inplace=True)\n",
        "prediction_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOdiJ9LJQKoo"
      },
      "outputs": [],
      "source": [
        "if 'sum_x' in count_df.columns:\n",
        "  count_df = count_df.drop(columns=['n_x', 'sum_x', 'sum_x2', 'mean_x', 'var_x'])\n",
        "\n",
        "if 'sum_x_x' in count_df.columns:\n",
        "  count_df = count_df.drop(columns=['n_x_x', 'sum_x_x', 'sum_x2_x', 'mean_x_x', 'var_x_x',\n",
        "                                    'n_x_y', 'sum_x_y', 'sum_x2_y', 'mean_x_y', 'var_x_y'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYHI9yq2jVP6"
      },
      "outputs": [],
      "source": [
        "# Generate summary statistics of scores in each well and add them to count_df\n",
        "prediction_df['pred_inhibition_logit_sq'] = prediction_df.pred_inhibition_logit ** 2.\n",
        "prediction_df['one'] = 1.\n",
        "pred_sum_df = prediction_df.groupby(['plate', 'well'])[['one', 'pred_inhibition_logit', 'pred_inhibition_logit_sq']].sum().rename(\n",
        "    columns={'one': 'n_x', 'pred_inhibition_logit': 'sum_x', 'pred_inhibition_logit_sq': 'sum_x2'})\n",
        "pred_mean_df = prediction_df.groupby(['plate', 'well'])[['pred_inhibition_logit']].mean().rename(\n",
        "    columns={'pred_inhibition_logit': 'mean_x'})\n",
        "pred_var_df = prediction_df.groupby(['plate', 'well'])[['pred_inhibition_logit']].var().rename(\n",
        "    columns={'pred_inhibition_logit': 'var_x'})\n",
        "prediction_df = prediction_df.drop(columns=['one'])\n",
        "\n",
        "count_df = count_df.merge(pred_sum_df, on=['plate', 'well'], how='left')\n",
        "count_df = count_df.merge(pred_mean_df, on=['plate', 'well'], how='left')\n",
        "count_df = count_df.merge(pred_var_df, on=['plate', 'well'], how='left')\n",
        "count_df['n_x'] = count_df['n_x'].fillna(0.)\n",
        "count_df['sum_x'] = count_df['sum_x'].fillna(0.)\n",
        "count_df['sum_x2'] = count_df['sum_x2'].fillna(0.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMHUBg4oJ_9a"
      },
      "outputs": [],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HHH1UXYzFcO"
      },
      "source": [
        "Look at how well the well mean of the appearance-based inhibition estimates predicts the count-based estimate for the well.\n",
        "\n",
        "The predictive power is still weak - the Spearman correlation is 0.27 - but it's an improvement over the 0.12 we got for a single hypnozoite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-TjhEDOIpGt"
      },
      "outputs": [],
      "source": [
        "# Look at how well mean predictions correspond to ML inhibition for samples.\n",
        "\n",
        "subset = (count_df[INHIBITION_COL] \u003c 1.) \u0026 (count_df.actives == 'sample')\n",
        "x = count_df[INHIBITION_COL][subset].to_numpy()\n",
        "y = count_df.mean_x[subset].to_numpy()\n",
        "print(scipy.stats.spearmanr(x, y))\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "alpha=0.1\n",
        "subset = np.random.choice(x.shape[0], 50000)\n",
        "x = x[subset]\n",
        "y = y[subset]\n",
        "sns.regplot(x=x,\n",
        "            y=y,\n",
        "            marker='.',\n",
        "            scatter_kws={'alpha': alpha},\n",
        "            line_kws={'color': 'orange'},\n",
        "            fit_reg=False,\n",
        "            )\n",
        "sub = x \u003e 0.005  # lowess has problems with big pile-up on the left\n",
        "\n",
        "lowess_mean = statsmodels.nonparametric.smoothers_lowess.lowess(y[sub], x[sub], frac=0.1, return_sorted=False)\n",
        "y_var = (y[sub] - lowess_mean) ** 2\n",
        "lowess_var = statsmodels.nonparametric.smoothers_lowess.lowess(y_var, x[sub], frac=0.1, return_sorted=False)\n",
        "idx = np.argsort(x[sub])\n",
        "\n",
        "x = x[sub][idx]\n",
        "lowess_mean = lowess_mean[idx]\n",
        "lowess_var = lowess_var[idx]\n",
        "\n",
        "x = np.concatenate([np.zeros(1), x])\n",
        "lowess_mean = np.concatenate([np.array([np.mean(y[~sub])]), lowess_mean])\n",
        "lowess_var = np.concatenate([np.array([np.var(y[~sub])]), lowess_var])\n",
        "\n",
        "plt.plot(x, lowess_mean, color='red', lw=3)\n",
        "plt.plot(x, lowess_mean + 2.*np.sqrt(lowess_var), color='red', ls='--')\n",
        "plt.plot(x, lowess_mean - 2.*np.sqrt(lowess_var), color='red', ls='--')\n",
        "plt.xlabel('Actual inhibition')\n",
        "plt.ylabel('Mean(predicted logit inhibition)')\n",
        "plt.title(f'Mean predicted {INHIBITION_TYPE} inhibition per well')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(x, lowess_var)\n",
        "plt.xlabel('Actual inhibition')\n",
        "plt.ylabel('Var(predicted logit inhibition)')\n",
        "plt.title(f'Variance of predicted {INHIBITION_TYPE} inhibition per well')\n",
        "plt.ylim(0, None)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ummlbyuWXAh"
      },
      "outputs": [],
      "source": [
        "# plot prediction variance vs ML inhibition\n",
        "subset = (count_df[COUNT_COL] \u003e 1) \u0026 (count_df.actives == 'sample')\n",
        "x = count_df[INHIBITION_COL][subset].to_numpy()\n",
        "y_var = count_df.var_x[subset].to_numpy()\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "alpha=0.1\n",
        "subset = np.random.choice(x.shape[0], 50000)\n",
        "sns.regplot(x=x[subset],\n",
        "            y=y_var[subset],\n",
        "            marker='.',\n",
        "            scatter_kws={'alpha': alpha},\n",
        "            line_kws={'color': 'orange'},\n",
        "            fit_reg=False,\n",
        "            )\n",
        "\n",
        "\n",
        "sub = x \u003e 0.001\n",
        "lowess_var = statsmodels.nonparametric.smoothers_lowess.lowess(y_var[sub], x[sub], frac=0.1, return_sorted=False)\n",
        "idx = np.argsort(x[sub])\n",
        "x = x[sub][idx]\n",
        "lowess_var = lowess_var[idx]\n",
        "plt.plot(x, lowess_var, color='red', lw=3)\n",
        "plt.xlabel('Actual inhibition')\n",
        "plt.ylabel('Var(predicted logit inhibition)')\n",
        "plt.title(f'Within well variance of predicted {INHIBITION_TYPE} inhibition')\n",
        "plt.ylim(0, 2.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABkwNK0LzbF3"
      },
      "source": [
        "### Covariates\n",
        "\n",
        "Here we break out appearance-based predictions for different hepatocyte lots for the control wells. We see that the predictions vary considerably from one hepatocyte lot to the next."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWXIGaKo--as"
      },
      "outputs": [],
      "source": [
        "# Break out within-well prediction means by hepatocyte lot.\n",
        "# There are big differences between lots!\n",
        "plt.figure(figsize=(8, 4))\n",
        "for i, (hep_lot, hep_df) in enumerate(count_df[count_df.actives!='sample'].groupby('hep_lot')):\n",
        "  color = COLORS[i]\n",
        "  x = hep_df[INHIBITION_COL]\n",
        "  y = hep_df.mean_x\n",
        "  sub = x \u003e 0.001\n",
        "  sns.regplot(x=x,\n",
        "              y=y,\n",
        "              label=hep_lot,\n",
        "              marker='.', color=color,\n",
        "              fit_reg=False,\n",
        "              scatter_kws={'alpha': 0.25})\n",
        "  lowess = statsmodels.nonparametric.smoothers_lowess.lowess(\n",
        "      y[sub], x[sub])\n",
        "  plt.plot(lowess[:, 0], lowess[:, 1], color=color, lw=3)\n",
        "legend = plt.legend(title='Hep lot', loc='best')\n",
        "for lh in legend.legendHandles:\n",
        "  lh.set_alpha(1)\n",
        "plt.xlabel('Actual inhibition')\n",
        "plt.ylabel('Mean(predicted logit inhibition)')\n",
        "plt.title(f'Mean predicted {INHIBITION_TYPE} inhibition by hepatocyte lot')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6kmtvMwtbpk"
      },
      "outputs": [],
      "source": [
        "# Break out within-well prediction variances by hepatocyte lot.\n",
        "# There are big differences between lots!\n",
        "plt.figure(figsize=(8, 4))\n",
        "for i, (hep_lot, hep_df) in enumerate(count_df[count_df.actives!='sample'].groupby('hep_lot')):\n",
        "  color = COLORS[i]\n",
        "  sns.regplot(x=hep_df[INHIBITION_COL],\n",
        "              y=hep_df.var_x, label=hep_lot,\n",
        "              marker='.', color=color,\n",
        "              fit_reg=False,\n",
        "              scatter_kws={'alpha': 0.25})\n",
        "  lowess = statsmodels.nonparametric.smoothers_lowess.lowess(\n",
        "      hep_df.var_x, hep_df[INHIBITION_COL])\n",
        "  plt.plot(lowess[:, 0], lowess[:, 1], color=color, lw=3)\n",
        "legend = plt.legend(title='Hep lot', loc='best')\n",
        "for lh in legend.legendHandles:\n",
        "  lh.set_alpha(1)\n",
        "plt.ylim(0, 2.5)\n",
        "plt.xlabel('Actual inhibition')\n",
        "plt.ylabel('Var(predicted logit inhibition)')\n",
        "plt.title(f'Within-well variance of predicted {INHIBITION_TYPE} inhibition by hepatocyte lot')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pd_ZpVShMtXd"
      },
      "outputs": [],
      "source": [
        "count_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz7hYGjhM1t2"
      },
      "source": [
        "## Combining appearance with counts: motivation\n",
        "\n",
        "The graph below shows the distribution of predicted inhibitions for individual hypnozoites as a function of the count-based estimates of inhibition in the well.\n",
        "\n",
        "The key thing to note is that in wells where the count inhibition is low (\u003c 0.25), the logits of the appearance predictions are mostly below -4. As the count inhibition increases, the apearance predictions shift rightward, with more and more predictions above -4.\n",
        "\n",
        "Below we will model the joint variation of appearance-based and count-based inhibition estimates to get a combined estimate of a drug candidate's impact on the parasites."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyX4kjZjayjo"
      },
      "outputs": [],
      "source": [
        "tmp_df = prediction_df[prediction_df['actives'] == 'sample'][[INHIBITION_COL, 'pred_inhibition_logit']].copy()\n",
        "label = np.array(['']*tmp_df.shape[0], dtype=object)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "n = 4\n",
        "for i in range(n):\n",
        "  lower = i/n\n",
        "  upper = (i+1)/n\n",
        "  subset = (tmp_df[INHIBITION_COL] \u003e= lower) \u0026 (tmp_df[INHIBITION_COL] \u003c upper)\n",
        "  label = ['count inhibition']\n",
        "  if i \u003e 0:\n",
        "    label = [f'{lower} \u003c='] + label\n",
        "  if i \u003c n-1:\n",
        "    label = label + [f'\u003c {upper}']\n",
        "  label = ' '.join(label)\n",
        "  sns.kdeplot(data=tmp_df[subset],\n",
        "              x='pred_inhibition_logit',\n",
        "              palette=sns.color_palette('tab10')[i],\n",
        "              lw=4,\n",
        "              label=label)\n",
        "plt.title('Appearance inhibition by count inhibition', fontsize=18)\n",
        "plt.xlabel('logit(predicted inhibition)', fontsize=16)\n",
        "plt.ylabel('Density', fontsize=16)\n",
        "plt.legend(loc='best', fontsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHqGQq0qz22W"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRfnCfHmCdMS"
      },
      "outputs": [],
      "source": [
        "# Put together some JAX arrays that will be used by our inhibition model\n",
        "treatment = []\n",
        "for (plate, well, actives) in zip(count_df.plate, count_df.well, count_df.actives):\n",
        "  if actives == 'infected_control':\n",
        "    treatment.append('infected_control')\n",
        "  elif actives == 'active_control':\n",
        "    treatment.append(f'active_control_{plate}')\n",
        "  elif actives == 'sample':\n",
        "    treatment.append(f'sample_{plate}_{well}')\n",
        "  else:\n",
        "    raise ValueError(f'Bad actives {actives}')\n",
        "count_df['treatment'] = treatment\n",
        "\n",
        "plates = sorted(set(count_df.plate))\n",
        "plate_to_plate_index = {plate: i for i, plate in enumerate(plates)}\n",
        "plate_index_to_plate = {i: plate for i, plate in enumerate(plates)}\n",
        "plate_index = [plate_to_plate_index[p] for p in count_df.plate]\n",
        "count_df['plate_index'] = plate_index\n",
        "\n",
        "treatments = sorted(set(count_df.treatment))\n",
        "treatments.remove('infected_control')\n",
        "treatments = ['infected_control'] + treatments\n",
        "treatment_to_treatment_index = {treatment: i for i, treatment in enumerate(treatments)}\n",
        "treatment_index_to_treatment = {i: plate for i, treatment in enumerate(treatments)}\n",
        "treatment_index = [treatment_to_treatment_index[t] for t in count_df.treatment]\n",
        "count_df['treatment_index'] = treatment_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZT5JQhNQR-k"
      },
      "outputs": [],
      "source": [
        "# Create a pytree containing the model parameters we'll optimize over\n",
        "n_plates = len(plates)\n",
        "n_treatments = len(treatments)\n",
        "n_hep_lots = len(set(count_df.hep_lot))\n",
        "\n",
        "key = jax.random.PRNGKey(0)\n",
        "key, subkey0, subkey1, subkey2, subkey3, subkey4, subkey5, subkey6 = jax.random.split(key, num=8)\n",
        "\n",
        "# spline parameters for the map between true inhibition and prediction score mean\n",
        "spline_order_mean = 3\n",
        "knots_mean = spline.set_knot_multiplicity(\n",
        "    k=spline_order_mean,\n",
        "    knots=tuple(np.linspace(joint_model.MIN_LOGIT_INHIBITION, joint_model.MAX_LOGIT_INHIBITION, num=5).tolist()))\n",
        "n_splines_mean = spline.n_basis_fns(k=spline_order_mean, knots=knots_mean)\n",
        "\n",
        "# spline parameters for the map between true inhibition and prediction score variance\n",
        "spline_order_var = 3\n",
        "knots_var = spline.set_knot_multiplicity(\n",
        "    k=spline_order_var,\n",
        "    knots=tuple(np.linspace(joint_model.MIN_LOGIT_INHIBITION, joint_model.MAX_LOGIT_INHIBITION, num=5).tolist()))\n",
        "n_splines_var = spline.n_basis_fns(k=spline_order_var, knots=knots_var)\n",
        "print(n_splines_mean, n_splines_var)\n",
        "\n",
        "# rough initial guess for the log(count) in an untreated well\n",
        "mean_items = np.log(np.mean(count_df[COUNT_COL][count_df.actives == 'infected_control']))\n",
        "\n",
        "# initial parameters that we will optimize\n",
        "initial_params = joint_model.InhibitionParams(\n",
        "    mean_items_unconstrained=jax.random.normal(key=subkey0, shape=(n_plates,)) + mean_items,\n",
        "    overdispersion_unconstrained=jax.random.normal(key=subkey1, shape=(n_plates,)),\n",
        "    inhibition_unconstrained=jax.random.normal(key=subkey2, shape=(n_treatments-1,)),\n",
        "    mean_coeffs_unconstrained=jax.random.normal(key=subkey3, shape=(n_hep_lots, n_splines_mean,)),\n",
        "    var_coeffs_unconstrained=jax.random.normal(key=subkey4, shape=(n_hep_lots, n_splines_var,)),\n",
        "    mean_offset_unconstrained=jax.random.normal(key=subkey5, shape=(n_plates,)),\n",
        "    var_offset_unconstrained=jax.random.normal(key=subkey6, shape=(n_plates,)),\n",
        "    spline_order_mean=spline_order_mean,\n",
        "    knots_mean=knots_mean,\n",
        "    spline_order_var=spline_order_var,\n",
        "    knots_var=knots_var,\n",
        "    min_logit_inhibition=joint_model.MIN_LOGIT_INHIBITION,\n",
        "    max_logit_inhibition=joint_model.MAX_LOGIT_INHIBITION,\n",
        "    max_mean_coeff=joint_model.MAX_MEAN_COEFF,\n",
        "    max_var_coeff=joint_model.MAX_VAR_COEFF,\n",
        "    constant_fields=set(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bCOAqpdTnbL"
      },
      "outputs": [],
      "source": [
        "# Step 1: Estimate inhibition using only the counts.\n",
        "\n",
        "# get the objective function for optimizing for counts only\n",
        "objective_count = joint_model.get_objective_count(count_df, COUNT_COL)\n",
        "\n",
        "# make sure the objective function doesn't blow up for the initial values\n",
        "print(objective_count(initial_params))\n",
        "\n",
        "value_and_grad_fn = jax.jit(jax.value_and_grad(objective_count))\n",
        "\n",
        "learning_rate = 0.1\n",
        "opt_init, opt_update = optax.chain(\n",
        "    optax.scale_by_adam(),\n",
        "    optax.scale(learning_rate)\n",
        ")\n",
        "\n",
        "params = initial_params\n",
        "state = opt_init(params)\n",
        "for i in range(2000):\n",
        "  value, grad = value_and_grad_fn(params)\n",
        "  if i % 100 == 0:\n",
        "    print(i, value, flush=True)\n",
        "  updates, state = opt_update(grad, state, params)\n",
        "  params = optax.apply_updates(params, updates)\n",
        "count_params = copy.deepcopy(params)\n",
        "count_df['inhibition_count'] = np.asarray(count_params.inhibition)[treatment_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSwkdoMuT8dN"
      },
      "outputs": [],
      "source": [
        "# Step 2: now we have some initial \"true\" inhibition estimates from above.\n",
        "# Use those to estimate the parameters for the splines that map true inhibition\n",
        "# to means and variances of prediction scores.\n",
        "\n",
        "objective_joint = joint_model.get_objective_joint(count_df, COUNT_COL)\n",
        "# make sure the objective function doesn't blow up for the initial values\n",
        "print(objective_joint(count_params))\n",
        "\n",
        "value_and_grad_fn = jax.jit(jax.value_and_grad(objective_joint))\n",
        "\n",
        "d = dataclasses.asdict(count_params)\n",
        "d['constant_fields'] = {'inhibition_unconstrained'}\n",
        "params = joint_model.InhibitionParams(**d)\n",
        "\n",
        "for learning_rate, steps in [(0.05, 200), (0.01, 1000)]:\n",
        "  opt_init, opt_update = optax.chain(\n",
        "      optax.scale_by_adam(),\n",
        "      optax.scale(learning_rate)\n",
        "  )\n",
        "\n",
        "  state = opt_init(params)\n",
        "  for i in range(steps):\n",
        "    value, grad = value_and_grad_fn(params)\n",
        "    if i % 100 == 0:\n",
        "      print(i, value, flush=True)\n",
        "    updates, state = opt_update(grad, state, params)\n",
        "    params = optax.apply_updates(params, updates)\n",
        "spline_params = copy.deepcopy(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJtGoZLIVrpI"
      },
      "outputs": [],
      "source": [
        "hep_lots = sorted(set(count_df.hep_lot))\n",
        "plate_index_by_hep_lot_index = {}\n",
        "for i in range(n_hep_lots):\n",
        "  plate_index_by_hep_lot_index[i] = sorted(set(count_df[count_df.hep_lot_index == i].plate_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-Ka3Eg1aPIA"
      },
      "outputs": [],
      "source": [
        "# Step 3: now that we have initial estimates for \"true\" inhibition and for\n",
        "# the spline parameters, do joint optimization for all parameters.\n",
        "value_and_grad_fn = jax.jit(jax.value_and_grad(objective_joint))\n",
        "\n",
        "d = dataclasses.asdict(spline_params)\n",
        "d['constant_fields'] = set()\n",
        "params = joint_model.InhibitionParams(**d)\n",
        "\n",
        "for learning_rate, steps in [(0.01, 2000)]:\n",
        "  opt_init, opt_update = optax.chain(\n",
        "      optax.scale_by_adam(),\n",
        "      optax.scale(learning_rate)\n",
        "  )\n",
        "\n",
        "  state = opt_init(params)\n",
        "  for i in range(steps):\n",
        "    value, grad = value_and_grad_fn(params)\n",
        "    if i % 100 == 0:\n",
        "      print(i, value, flush=True)\n",
        "    updates, state = opt_update(grad, state, params)\n",
        "    params = optax.apply_updates(params, updates)\n",
        "joint_params = copy.deepcopy(params)\n",
        "count_df['inhibition_joint'] = np.asarray(joint_params.inhibition)[treatment_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNNJulkcbPZG"
      },
      "outputs": [],
      "source": [
        "# Visualize the splines mapping inhibition to mean/variance of predictions\n",
        "x = jnp.arange(joint_model.MIN_LOGIT_INHIBITION, joint_model.MAX_LOGIT_INHIBITION, 0.01)\n",
        "n_hep_lots = len(hep_lots)\n",
        "\n",
        "fig, axes = plt.subplots(1, n_hep_lots, figsize=(2*n_hep_lots, 2), sharex=True, sharey=True)\n",
        "for i, hep_lot in enumerate(hep_lots):\n",
        "  color = COLORS[i]\n",
        "  for j, plate_index in enumerate(plate_index_by_hep_lot_index[i]):\n",
        "    pred_mean = joint_params.pred_mean(\n",
        "        x,\n",
        "        spline_index=i,\n",
        "        offset_index=plate_index,\n",
        "        k=spline_order_mean,\n",
        "        knots=knots_mean)\n",
        "    expit_x = jax.scipy.special.expit(x)\n",
        "    axes[i].plot(expit_x, pred_mean, color=color, label=hep_lot)\n",
        "  axes[i].set_xlabel('inhibition')\n",
        "  if i == 0:\n",
        "    axes[i].set_ylabel('mean_score(inhibition)')\n",
        "  axes[i].set_ylim(-6, 0.)\n",
        "  axes[i].set_title(f'{hep_lot}')\n",
        "plt.show()\n",
        "\n",
        "fig, axes = plt.subplots(1, n_hep_lots, figsize=(2*n_hep_lots, 2), sharex=True, sharey=True)\n",
        "for i, hep_lot in enumerate(hep_lots):\n",
        "  color = COLORS[i]\n",
        "  for j, plate_index in enumerate(plate_index_by_hep_lot_index[i]):\n",
        "    pred_var = joint_params.pred_var(\n",
        "        x,\n",
        "        spline_index=i,\n",
        "        offset_index=plate_index,\n",
        "        k=spline_order_var,\n",
        "        knots=knots_var)\n",
        "    expit_x = jax.scipy.special.expit(x)\n",
        "    axes[i].plot(expit_x, pred_var, color=color, label=hep_lot)\n",
        "  axes[i].set_xlabel('inhibition')\n",
        "  if i == 0:\n",
        "    axes[i].set_ylabel('var_score(inhibition)')\n",
        "  axes[i].set_ylim(0, 2.5)\n",
        "  axes[i].set_title(f'{hep_lot}')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62gz4av1bBpT"
      },
      "outputs": [],
      "source": [
        "# Step 4 (bonus): Get an appearance inhibition score by finding the true\n",
        "# inhibition that maximizes just the appearance loss (we'll use the spline\n",
        "# parameters fit above)\n",
        "objective_appearance = joint_model.get_objective_appearance(count_df)\n",
        "value_and_grad_fn = jax.jit(jax.value_and_grad(objective_appearance))\n",
        "\n",
        "d = dataclasses.asdict(joint_params)\n",
        "constant_fields = set(d.keys())\n",
        "constant_fields.remove('inhibition_unconstrained')\n",
        "d['constant_fields'] = constant_fields\n",
        "params = joint_model.InhibitionParams(**d)\n",
        "\n",
        "for learning_rate, steps in [(0.1, 1000)]:\n",
        "  opt_init, opt_update = optax.chain(\n",
        "      optax.scale_by_adam(),\n",
        "      optax.scale(learning_rate)\n",
        "  )\n",
        "\n",
        "  state = opt_init(params)\n",
        "  for i in range(steps):\n",
        "    value, grad = value_and_grad_fn(params)\n",
        "    if i % 100 == 0:\n",
        "      print(i, value, flush=True)\n",
        "    updates, state = opt_update(grad, state, params)\n",
        "    params = optax.apply_updates(params, updates)\n",
        "appearance_params = copy.deepcopy(params)\n",
        "\n",
        "inhibition_appearance = np.asarray(appearance_params.inhibition)[treatment_index]\n",
        "inhibition_appearance[count_df[COUNT_COL] == 0] = 1.\n",
        "count_df['inhibition_appearance'] = inhibition_appearance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PFjTLxiKIio"
      },
      "outputs": [],
      "source": [
        "# Look at relationship between count inhibition and appearance inhibition\n",
        "plt.figure(figsize=(8, 4))\n",
        "subset = count_df.actives == 'sample'\n",
        "plt.scatter(count_df.inhibition_count[subset],\n",
        "            count_df.inhibition_appearance[subset],\n",
        "            marker='.', alpha=0.25)\n",
        "plt.plot((0, 1), (0, 1), color='gray', ls='--')\n",
        "plt.xlabel('Count inhibition')\n",
        "plt.ylabel('Appearance inhibition')\n",
        "plt.title(f'Count based vs appearance based inhibition, {INHIBITION_TYPE}')\n",
        "plt.show()\n",
        "print(scipy.stats.spearmanr(count_df.inhibition_count[subset],\n",
        "                            count_df.inhibition_appearance[subset]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8P38OAkIzVY"
      },
      "outputs": [],
      "source": [
        "# Look at relationship between count inhibition and appearance inhibition\n",
        "# broken out by hepatocyte lot\n",
        "\n",
        "xcol = 'inhibition_count'\n",
        "ycol = 'inhibition_appearance'\n",
        "\n",
        "subset = (count_df.actives == 'sample') \u0026 (np.isfinite(count_df[ycol]))\n",
        "plt.figure(figsize=(8, 4))\n",
        "for i, (hep_lot, hep_df) in enumerate(count_df[subset].groupby('hep_lot')):\n",
        "  color = COLORS[i]\n",
        "  x = hep_df[xcol]\n",
        "  y = hep_df[ycol]\n",
        "  sns.regplot(x=x,\n",
        "              y=y,\n",
        "              marker='.',\n",
        "              fit_reg=False,\n",
        "              scatter_kws={'alpha':0.25},)\n",
        "  lowess = statsmodels.nonparametric.smoothers_lowess.lowess(y, x, 0.25)\n",
        "  plt.plot(lowess[:, 0], lowess[:, 1], color=color, lw=3, label=hep_lot)\n",
        "plt.xlabel('Count inhibition')\n",
        "plt.ylabel('Appearance inhibition')\n",
        "plt.title(f'Count based vs appearance based inhibition, {INHIBITION_TYPE}')\n",
        "plt.ylim(0, 1)\n",
        "legend = plt.legend(loc='best', title='Hep lot')\n",
        "for lh in legend.legendHandles:\n",
        "  lh.set_alpha(1)\n",
        "plt.show()\n",
        "print(scipy.stats.spearmanr(count_df[xcol][subset], count_df[ycol][subset]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSdWM52fKSWd"
      },
      "outputs": [],
      "source": [
        "# Look at relationship between count inhibition and joint inhibition\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "subset = count_df.actives == 'sample'\n",
        "plt.scatter(count_df.inhibition_count[subset],\n",
        "            count_df.inhibition_joint[subset],\n",
        "            marker='.', alpha=0.25)\n",
        "plt.plot((0, 1), (0, 1), color='gray', ls='--', lw=2)\n",
        "plt.xlabel('Count inhibition')\n",
        "plt.ylabel('Joint inhibition')\n",
        "plt.title(f'Count based vs joint inhibition, {INHIBITION_TYPE}')\n",
        "plt.show()\n",
        "print(scipy.stats.spearmanr(count_df.inhibition_count[subset], count_df.inhibition_joint[subset]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xebzs_59JMRw"
      },
      "outputs": [],
      "source": [
        "# Look at relationship between count inhibition and joint inhibition\n",
        "# broken out by hepatocyte lot\n",
        "\n",
        "xcol = 'inhibition_count'\n",
        "ycol = 'inhibition_joint'\n",
        "\n",
        "subset = (count_df.actives == 'sample') \u0026 (np.isfinite(count_df[ycol]))\n",
        "plt.figure(figsize=(8, 4))\n",
        "for i, (hep_lot, hep_df) in enumerate(count_df[subset].groupby('hep_lot')):\n",
        "  color = COLORS[i]\n",
        "  x = hep_df[xcol]\n",
        "  y = hep_df[ycol]\n",
        "  sns.regplot(x=x,\n",
        "              y=y,\n",
        "              marker='.',\n",
        "              fit_reg=False,\n",
        "              scatter_kws={'alpha':0.25},)\n",
        "  lowess = statsmodels.nonparametric.smoothers_lowess.lowess(y, x, frac=0.15)\n",
        "  plt.plot(lowess[:, 0], lowess[:, 1], color=color, lw=3, label=hep_lot)\n",
        "plt.xlabel('Count inhibition')\n",
        "plt.ylabel('Joint inhibition')\n",
        "plt.title(f'Count based vs joint inhibition, {INHIBITION_TYPE}')\n",
        "legend = plt.legend(loc='best', title='Hep lot')\n",
        "for lh in legend.legendHandles:\n",
        "  lh.set_alpha(1)\n",
        "plt.show()\n",
        "print(scipy.stats.spearmanr(count_df[xcol][subset], count_df[ycol][subset]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LLuKnHgUL6k"
      },
      "outputs": [],
      "source": [
        "# load dose response estimates\n",
        "dr_df = pd.read_parquet(DOSE_RESPONSE_FILE)\n",
        "\n",
        "COLS_TO_KEEP = ['batch', 'plate', 'well', 'embedding', 'actives', 'hep_lot',\n",
        "                'ml_hypnozoite', 'inhibition_ml_hyp', 'ml_parasite',\n",
        "                'inhibition_ml_par', 'hep_lot_index']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7ZtlGKKK_0a"
      },
      "outputs": [],
      "source": [
        "dr_df.rename(columns={'compound': 'blinded_concept'}, inplace=True)\n",
        "dr_df = dr_df.groupby('blinded_concept').median().reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBsBgv_0pZVO"
      },
      "outputs": [],
      "source": [
        "dr_df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYRevfMK_bck"
      },
      "outputs": [],
      "source": [
        "# Measures of inhibition to compare as predictors of IC50/CC50\n",
        "MEASURES = ['inhibition_cp_hyp_act',  # cell-profiler based counts with correction based on active control inhibition\n",
        "            'inhibition_cp_hyp',      # cell-profiler based counts\n",
        "            'inhibition_ml_hyp',      # ml based counts\n",
        "            'inhibition_count',       # ml based counts (maximum likelihood estimate)\n",
        "            'inhibition_appearance',  # appearance based estimate\n",
        "            'inhibition_joint',       # joint estimate based on ml counts and appearance\n",
        "            ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEXYVLUuK__t"
      },
      "outputs": [],
      "source": [
        "sample_df = count_df[(count_df.actives == 'sample') \u0026 (count_df.blinded_concept != 'none')].copy()\n",
        "sample_df = sample_df.groupby('blinded_concept')[MEASURES].median().reset_index()\n",
        "\n",
        "# Join screen measures and IC50 estimates\n",
        "joined_df = sample_df.merge(dr_df, how='inner', on=['blinded_concept']).reset_index()\n",
        "joined_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsYJj94Jhyxo"
      },
      "outputs": [],
      "source": [
        "# Compute AUCs for predictors of IC50/CC50 being below different thresholds\n",
        "TARGET_COL = 'log_ic50'\n",
        "TARGET_NAME = 'IC50'\n",
        "\n",
        "for t in [10, 3, 1, 0.3]:\n",
        "  y = joined_df[TARGET_COL] \u003c np.log(t)\n",
        "  print(f'Threshold {t}: {np.sum(y)} / {y.shape[0]} compounds have {TARGET_NAME} \u003c threshold')\n",
        "  for measure in MEASURES:\n",
        "    print(f'AUC, {measure:25s} {sklearn.metrics.roc_auc_score(y, joined_df[measure]):.3f}')\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MBW-PToniSf"
      },
      "outputs": [],
      "source": [
        "# Look at patch scores as a function of total ML inhibition (count-based)\n",
        "BINS = 200\n",
        "plt.figure(figsize=(8, 4))\n",
        "subset = (prediction_df[INHIBITION_COL] \u003c 0.25)\n",
        "plt.hist(prediction_df.pred_inhibition_logit[(prediction_df.actives == 'sample') \u0026 subset], bins=BINS, alpha=0.7, density=True,\n",
        "         label='count inhibition \u003c 0.25')\n",
        "subset = (prediction_df[INHIBITION_COL] \u003e= 0.25) \u0026 (prediction_df[INHIBITION_COL] \u003c 0.5)\n",
        "plt.hist(prediction_df.pred_inhibition_logit[(prediction_df.actives == 'sample') \u0026 subset], bins=BINS, alpha=0.6, density=True,\n",
        "         label='0.25 \u003c= count inhibition \u003c 0.5')\n",
        "subset = (prediction_df[INHIBITION_COL] \u003e= 0.5) \u0026 (prediction_df[INHIBITION_COL] \u003c 0.75)\n",
        "plt.hist(prediction_df.pred_inhibition_logit[(prediction_df.actives == 'sample') \u0026 subset], bins=BINS, alpha=0.5, density=True,\n",
        "                  label='0.5 \u003c= count inhibition \u003c 0.75')\n",
        "subset = (prediction_df[INHIBITION_COL] \u003e= 0.75)\n",
        "plt.hist(prediction_df.pred_inhibition_logit[(prediction_df.actives == 'sample') \u0026 subset], bins=BINS, alpha=0.4, density=True,\n",
        "         label='0.75 \u003c= count inhibition')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('Model prediction (logit scale)') #, fontsize=16)\n",
        "plt.ylabel(f'{INHIBITION_TYPE.capitalize()} density') #, fontsize=16)\n",
        "plt.title('Predicted inhibition') #, fontsize=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTAAmX3vFJTd"
      },
      "source": [
        "# Visualize parasites with different scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0M8LIIcFMfU"
      },
      "outputs": [],
      "source": [
        "from cell_img.common import image_lib\n",
        "from cell_img.malaria_liver import metadata_lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "id_XoZjBFdub"
      },
      "outputs": [],
      "source": [
        "# set up the object to create images based on metadata\n",
        "meta_ts = metadata_lib.MetadataIndex(TENSORSTORE_PATH, CHANNEL_TO_RGB,\n",
        "                                     METADATA_ROOT_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxAOKRt2cwl2"
      },
      "outputs": [],
      "source": [
        "prediction_df.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCzSt5NFnIJM"
      },
      "outputs": [],
      "source": [
        "# Display a random sample of hypnozoites\n",
        "np.random.seed(123)\n",
        "query_str = 'actives == \"sample\"'\n",
        "nrows = 8\n",
        "ncols = 8\n",
        "\n",
        "subset_df = prediction_df.query(query_str)\n",
        "print('There are %d patches with %s, subsetting %d' % (\n",
        "    len(subset_df), query_str, ncols*nrows))\n",
        "\n",
        "sampled_subset = subset_df.sample(ncols*nrows)\n",
        "\n",
        "_ = meta_ts.contact_sheet_for_df(\n",
        "    example_df=sampled_subset,\n",
        "    patch_size=50, ncols=ncols, nrows=nrows,\n",
        "    name_for_x_col='center_col', name_for_y_col='center_row',\n",
        "    norm_then_stack=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1lzA5coHkS_"
      },
      "outputs": [],
      "source": [
        "# Display very happy hypnozoites (pred_inhibition \u003c -5)\n",
        "np.random.seed(123)\n",
        "query_str = 'actives == \"sample\" and pred_inhibition_logit \u003c -5'\n",
        "nrows = 8\n",
        "ncols = 8\n",
        "\n",
        "subset_df = prediction_df.query(query_str)\n",
        "print('There are %d patches with %s, subsetting %d' % (\n",
        "    len(subset_df), query_str, ncols*nrows))\n",
        "\n",
        "sampled_subset = subset_df.sample(ncols*nrows)\n",
        "\n",
        "_ = meta_ts.contact_sheet_for_df(\n",
        "    example_df=sampled_subset,\n",
        "    patch_size=50, ncols=ncols, nrows=nrows,\n",
        "    name_for_x_col='center_col', name_for_y_col='center_row',\n",
        "    norm_then_stack=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFicE5ruFvWV"
      },
      "outputs": [],
      "source": [
        "# Display happy hypnozoites (pred_inhibition \u003c -4)\n",
        "np.random.seed(123)\n",
        "query_str = 'actives == \"sample\" and pred_inhibition_logit \u003c -4'\n",
        "nrows = 8\n",
        "ncols = 8\n",
        "\n",
        "subset_df = prediction_df.query(query_str)\n",
        "print('There are %d patches with %s, subsetting %d' % (\n",
        "    len(subset_df), query_str, ncols*nrows))\n",
        "\n",
        "sampled_subset = subset_df.sample(ncols*nrows)\n",
        "\n",
        "_ = meta_ts.contact_sheet_for_df(\n",
        "    example_df=sampled_subset,\n",
        "    patch_size=50, ncols=ncols, nrows=nrows,\n",
        "    name_for_x_col='center_col', name_for_y_col='center_row',\n",
        "    norm_then_stack=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1WYu0RBtbVP"
      },
      "outputs": [],
      "source": [
        "# Display stressed hypnozoites (pred_inhibition \u003e -4)\n",
        "np.random.seed(123)\n",
        "query_str = 'actives == \"sample\" and pred_inhibition_logit \u003e -4'\n",
        "nrows = 8\n",
        "ncols = 8\n",
        "\n",
        "subset_df = prediction_df.query(query_str)\n",
        "print('There are %d patches with %s, subsetting %d' % (\n",
        "    len(subset_df), query_str, ncols*nrows))\n",
        "\n",
        "sampled_subset = subset_df.sample(ncols*nrows)\n",
        "\n",
        "_ = meta_ts.contact_sheet_for_df(\n",
        "    example_df=sampled_subset,\n",
        "    patch_size=50, ncols=ncols, nrows=nrows,\n",
        "    name_for_x_col='center_col', name_for_y_col='center_row',\n",
        "    norm_then_stack=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ec5rOW-47N4l"
      },
      "outputs": [],
      "source": [
        "# Display very stressed hypnozoites (pred_inhibition \u003e -3)\n",
        "np.random.seed(123)\n",
        "query_str = 'actives == \"sample\" and pred_inhibition_logit \u003e -3'\n",
        "nrows = 8\n",
        "ncols = 8\n",
        "\n",
        "subset_df = prediction_df.query(query_str)\n",
        "print('There are %d patches with %s, subsetting %d' % (\n",
        "    len(subset_df), query_str, ncols*nrows))\n",
        "\n",
        "sampled_subset = subset_df.sample(ncols*nrows)\n",
        "\n",
        "_ = meta_ts.contact_sheet_for_df(\n",
        "    example_df=sampled_subset,\n",
        "    patch_size=50, ncols=ncols, nrows=nrows,\n",
        "    name_for_x_col='center_col', name_for_y_col='center_row',\n",
        "    norm_then_stack=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7euYzDXZ4JJG"
      },
      "outputs": [],
      "source": [
        "if INHIBITION_TYPE in {'hypnozoite', 'parasite'}:\n",
        "  STRESSED_HEP_LOT = 'KOG'\n",
        "  HAPPY_HEP_LOT = 'HTV'\n",
        "\n",
        "# things look more stressed in some hep lots\n",
        "np.random.seed(123)\n",
        "nrows = 8\n",
        "ncols = 8\n",
        "\n",
        "subset = ((prediction_df.actives == 'sample') \u0026\n",
        "          (prediction_df.hep_lot == STRESSED_HEP_LOT) \u0026\n",
        "          (prediction_df[INHIBITION_COL] \u003e 0.1) \u0026\n",
        "          (prediction_df[INHIBITION_COL] \u003c= 0.2))\n",
        "subset_df = prediction_df[subset]\n",
        "print('There are %d patches with %s, subsetting %d' % (\n",
        "    len(subset_df), query_str, ncols*nrows))\n",
        "\n",
        "sampled_subset = subset_df.sample(ncols*nrows)\n",
        "\n",
        "_ = meta_ts.contact_sheet_for_df(\n",
        "    example_df=sampled_subset,\n",
        "    patch_size=50, ncols=ncols, nrows=nrows,\n",
        "    name_for_x_col='center_col', name_for_y_col='center_row',\n",
        "    norm_then_stack=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JErwjOso4Uuq"
      },
      "outputs": [],
      "source": [
        "# things look less stressed in some hep lots\n",
        "np.random.seed(123)\n",
        "\n",
        "subset = ((prediction_df.actives == 'sample') \u0026\n",
        "          (prediction_df.hep_lot == HAPPY_HEP_LOT) \u0026\n",
        "          (prediction_df[INHIBITION_COL] \u003e 0.1) \u0026\n",
        "          (prediction_df[INHIBITION_COL] \u003c= 0.2))\n",
        "subset_df = prediction_df[subset]\n",
        "print('There are %d patches with %s, subsetting %d' % (\n",
        "    len(subset_df), query_str, ncols*nrows))\n",
        "\n",
        "sampled_subset = subset_df.sample(ncols*nrows)\n",
        "\n",
        "_ = meta_ts.contact_sheet_for_df(\n",
        "    example_df=sampled_subset,\n",
        "    patch_size=50, ncols=ncols, nrows=nrows,\n",
        "    name_for_x_col='center_col', name_for_y_col='center_row',\n",
        "    norm_then_stack=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2FH_xxwGe6y"
      },
      "source": [
        "# Save out predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h15M3FoOwmZw"
      },
      "outputs": [],
      "source": [
        "print(f'Writing to:\\n{INHIBITION_FILE}')\n",
        "\n",
        "count_df[['batch', 'plate', 'well', 'actives', 'blinded_concept', 'hep_lot',\n",
        "            'ml_hypnozoite', 'ml_schizont', 'ml_parasite',\n",
        "            'inhibition_ml_hyp', 'inhibition_ml_par',\n",
        "            'inhibition_count', 'inhibition_appearance', 'inhibition_joint']].to_parquet(INHIBITION_FILE)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
