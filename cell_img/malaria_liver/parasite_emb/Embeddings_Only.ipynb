{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpJSLNA2AyJe"
      },
      "source": [
        "# Embedding Creation Only\n",
        "\n",
        "The standard open source pipeline takes in whole images, performs object detection and lifecycle stage classification, and saves extracted patches with embeddings.\n",
        "\n",
        "The \"Emb Creation Only\" version of the pipeline takes the whole site images as input, but also takes a CSV file with parasite centers identified in another application (like CellProfiler). This pipeline extracts the patches and saves the patches and their embeddings.\n",
        "\n",
        "Because the ML model used to create embeddings from images is a model that is publicly available on TensorFlow hub, this version of the embedding creation pipeline requires no custom ML models.\n",
        "\n",
        "Both pipelines perform the crop/center/rotate function which reduces noise from uncentered parasite patches. (Our work showed that if you cluster parasites that are uncentered, you'll see clusters with different parasite locations - so instead of one \"healthy parasites\" group, you might see three with healthy parasites in different locations with the patch.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fy2Ilk40C2Zu"
      },
      "outputs": [],
      "source": [
        "#@title Run this cell only the FIRST time you connect to the colab kernel\n",
        "!pip install gcsfs\n",
        "!git clone https://github.com/google/cell_img\n",
        "!pip install --quiet -e cell_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvWjmmWqCe0_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "import cell_img\n",
        "from cell_img.common import data_utils\n",
        "from cell_img.common import image_lib\n",
        "from cell_img.malaria_liver import metadata_lib\n",
        "from cell_img.malaria_liver.parasite_emb import make_embeddings_main_lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0Pob0p6zFps"
      },
      "outputs": [],
      "source": [
        "#@title Run this cell after restarting your kernel. It will pop up window to grant access.\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3vg0cyWKaFN"
      },
      "outputs": [],
      "source": [
        "# Set up file paths\n",
        "DATA_ROOT = 'gs://path/to/public/data'\n",
        "INPUT_IMAGE_CSV = os.path.join(DATA_ROOT, 'tensorstore/metadata/test_emb_only_creation/input_images.csv')\n",
        "INPUT_OBJECT_CSV = os.path.join(DATA_ROOT, 'tensorstore/metadata/test_emb_only_creation/input_objects.csv')\n",
        "\n",
        "# Write locally to this colab,\n",
        "# This path should be a cloud bucket for non-examples.\n",
        "OUTPUT_DIR = 'example_output_dir'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_F1vM_XEH6N4"
      },
      "source": [
        "# Run the pipeline within the colab\n",
        "\n",
        "This example runs the model within this colab for this small test dataset.\n",
        "\n",
        "To run a cloud dataflow job for larger datasets, use the pipeline options and docker installation in the \"Create Embeddings for Parasites\" colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWZWZlMjIW85"
      },
      "outputs": [],
      "source": [
        "def run_pipeline(image_csv_path, object_metadata_csv_path, output_dir,\n",
        "                 whole_image_size, num_output_shards=10, options=None):\n",
        "\n",
        "  # For most of the options, we hardcode the correct values for our\n",
        "  # pipeline. Most of these options shouldn't ever change.\n",
        "  pipeline_result = make_embeddings_main_lib.run_emb_creation_only_pipeline(\n",
        "    image_csv=image_csv_path,\n",
        "    object_metadata_csv=object_metadata_csv_path,\n",
        "    raw_channel_order=['w1', 'w2', 'w3'],\n",
        "    channel_order=['DAPI', 'PVM', 'HSP70'],\n",
        "    whole_image_size=whole_image_size,\n",
        "    log_brightness_min=[-7., -7., -7.],\n",
        "    log_brightness_max=[0., 0., 0.],\n",
        "    output_dir=output_dir,\n",
        "    pixels_per_side=64,\n",
        "    num_output_shards=num_output_shards,\n",
        "    count_csv_dir='count_csvs',\n",
        "    crop_size=32,\n",
        "    stain_indices=[2, 1],\n",
        "    do_rotate=True,\n",
        "    do_center=True,\n",
        "    batch_size=128,\n",
        "    embedding_model_path='https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_s/feature_vector/2',\n",
        "    embedding_model_output_size=64,\n",
        "    embedding_model_output_seed=2342343,\n",
        "    options=options)\n",
        "\n",
        "  if hasattr(pipeline_result, '_job'):\n",
        "    # It was launched on cloud dataflow. Print the URL for the job.\n",
        "    url = ('https://console.cloud.google.com/dataflow/jobs/%s/%s?project=%s' %\n",
        "          (pipeline_result._job.location,\n",
        "          pipeline_result._job.id,\n",
        "          pipeline_result._job.projectId))\n",
        "    print(url)\n",
        "  return pipeline_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1EDda1YJC_2"
      },
      "outputs": [],
      "source": [
        "run_pipeline(\n",
        "    image_csv_path=INPUT_IMAGE_CSV, \n",
        "    object_metadata_csv_path=INPUT_OBJECT_CSV, \n",
        "    output_dir=OUTPUT_DIR,\n",
        "    whole_image_size=[2048,2048], \n",
        "    num_output_shards=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye08yejIIXwC"
      },
      "source": [
        "# Validating input data and results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFDk56M-DDAB"
      },
      "outputs": [],
      "source": [
        "input_df = pd.read_csv(INPUT_OBJECT_CSV)\n",
        "\n",
        "# Reading CSVs require re-formatting some columns to align to our expectations.\n",
        "input_df['plate'] = input_df['plate'].astype(str).apply(\n",
        "      lambda x: x.split('.')[0].zfill(5))\n",
        "input_df['plate_uid'] = input_df['plate']\n",
        "input_df['site'] = input_df['site'].apply(\n",
        "    lambda s: str(s).zfill(5))\n",
        "# If the CSV was saved with no index, drop the unnamed column\n",
        "unnamed_c = [c for c in input_df.columns if c.startswith('Unnamed:')]\n",
        "if unnamed_c:\n",
        "  input_df = input_df.drop(columns=unnamed_c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_K6IFA5CDfVN"
      },
      "outputs": [],
      "source": [
        "input_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QmSfKBxkYDf"
      },
      "outputs": [],
      "source": [
        "# read in the results to compare against our input\n",
        "output_df_list = []\n",
        "for i in range(2):\n",
        "  output_df_list.append(pd.read_parquet(os.path.join(OUTPUT_DIR, 'patches.parquet-0000%d-of-00002' % i)))\n",
        "output_df = pd.concat(output_df_list)\n",
        "output_df.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CP-5mQymwnCp"
      },
      "outputs": [],
      "source": [
        "print('There were %d parasites in the input, and there are %d in the output' % (\n",
        "    len(input_df), len(output_df)\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXEU5_f16cwm"
      },
      "outputs": [],
      "source": [
        "edge_query_str = 'center_row \u003c 60 or center_row \u003e 2000 or center_col \u003c 60 or center_col \u003e 2000'\n",
        "\n",
        "input_on_edge_df = input_df.query(edge_query_str)\n",
        "output_on_edge_df = output_df.query(edge_query_str)\n",
        "\n",
        "print('In the input, there are %d parasites on the edge of images but in the output there are only %d' %\n",
        "      (len(input_on_edge_df), len(output_on_edge_df)))\n",
        "\n",
        "print('There are %d more parasites in input than output, and %d more eduge parasites' % (\n",
        "    (len(input_df) - len(output_df), \n",
        "     len(input_on_edge_df) - len(output_on_edge_df))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nF9fNd5Wy0wh"
      },
      "outputs": [],
      "source": [
        "# The centers will not be exact because of the crop/center/rotate, we can\n",
        "# sort and then directly compare these lists\n",
        "input_on_edge_df.sort_values(['center_row', 'center_col'])[\n",
        "    ['batch', 'plate', 'well', 'site', 'center_row', 'center_col']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swla8VxqzCvn"
      },
      "outputs": [],
      "source": [
        "output_on_edge_df.sort_values(['center_row', 'center_col'])[\n",
        "    ['batch', 'plate', 'well', 'site', 'center_row', 'center_col']]\n",
        "\n",
        "# this makes it clear that the parasites with center_row \u003c 53 or\n",
        "# center_row \u003e 2015 are listed above on the input but not below\n",
        "# on the output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8HxqEDZHjJ3"
      },
      "source": [
        "## Validation: Look at parasite centers\n",
        "\n",
        "We don't expect these to change, so we are just validating that they look the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5M0_e20iGrxk"
      },
      "outputs": [],
      "source": [
        "# Path for where to find the CSVs with the information needed to create the\n",
        "# tensorstore: image paths and where, within the image_grid, to place each image.\n",
        "TENSORSTORE_PATH = os.path.join(DATA_ROOT, 'tensorstore')\n",
        "METADATA_ROOT = os.path.join(TENSORSTORE_PATH, 'metadata')\n",
        "TS_CSV_FOLDER = 'tensorstore'\n",
        "CHANNEL_TO_RGB = ['w3', 'w2', 'w1']\n",
        "\n",
        "# Set up the alignment between our channel names and RGB\n",
        "CHANNEL_TO_RGB = ['w3', 'w2', 'w1']\n",
        "meta_ts = metadata_lib.MetadataIndex(\n",
        "    TENSORSTORE_PATH, CHANNEL_TO_RGB, METADATA_ROOT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rTWy87y8mds"
      },
      "outputs": [],
      "source": [
        "# pick a set of parasites to look at\n",
        "input_df.query('well == \"J12\" and site == \"00013\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Y_q1TwJG7Y6"
      },
      "outputs": [],
      "source": [
        "df_to_show = input_df.query('well == \"J12\" and site == \"00013\"').sort_values(\n",
        "    ['center_row', 'center_col']\n",
        ")\n",
        "fig = meta_ts.contact_sheet_for_df(\n",
        "    example_df=df_to_show, patch_size=40, ncols=3, nrows=1,\n",
        "    name_for_x_col='center_col', name_for_y_col='center_row')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6y3xnvyHLnC"
      },
      "outputs": [],
      "source": [
        "# Look at the same set of parasites in the output dataframe\n",
        "df_to_show = output_df.query('well == \"J12\" and site == \"00013\"').sort_values(\n",
        "    ['center_row', 'center_col']\n",
        ")\n",
        "fig = meta_ts.contact_sheet_for_df(\n",
        "    example_df=df_to_show, patch_size=40, ncols=3, nrows=1,\n",
        "    name_for_x_col='center_col', name_for_y_col='center_row')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1qG0Vfv7pC5MLUFIKPRB72cLpmkDpSa0S",
          "timestamp": 1680294558085
        },
        {
          "file_id": "1UTK9IOEzlC-KMltsKsjnGZMl6EBi1Mvl",
          "timestamp": 1680038652906
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
