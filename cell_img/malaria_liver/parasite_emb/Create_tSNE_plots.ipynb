{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LizJ7EK1YBW-"
      },
      "source": [
        "# tSNE Template\n",
        "\n",
        "This colab is designed to create tSNE plots of the well mean embedding of hypnozoites to see which wells are like other wells.\n",
        "\n",
        "* The data for this notebook is the \"well mean embedding of hypnozoites\":\n",
        "  * The schizonts and artifacts are ignored.\n",
        "  * The embeddings for all the hypnozoites in a well are averaged by simply taking the mean in each of the 192 dimensions.\n",
        "  * By default, the DAPI stain (the first 64 of the 192 dimensions) is dropped because we want to look at the parasite-specific stains.\n",
        "  * Thus the result for each well is a single 128-dimensional embedding vector. So the plots have one dot for each well in the graph.\n",
        "  * [tSNE](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding) is a method for reducing dots in a high dimensional space into 2 dimensions for better visualization.\n",
        "  * If you want to think about or measure the true distance between the dots, you want to go back to the embeddings, for example you can do [k-means clustering](https://en.wikipedia.org/wiki/K-means_clustering) on the well mean embeddings.\n",
        "\n",
        "===========\n",
        "\n",
        "This colab is a TEMPLATE! To get started, CREATE A COPY, delete this text and type your goal with this colab.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zd5AUPv0EZqA"
      },
      "outputs": [],
      "source": [
        "#@title Run this cell only the FIRST time you connect to the colab kernel\n",
        "!pip install gcsfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VZinSS6Ezpy"
      },
      "outputs": [],
      "source": [
        "#@title (Not required for connection to the Google Research Bucket) Run this cell after restarting your kernel\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doHxPrNPsmOS"
      },
      "outputs": [],
      "source": [
        "DATA_ROOT = 'gs://path/to/your/data/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTHTbIZSFihB"
      },
      "outputs": [],
      "source": [
        "GCS_PROJECT = 'your_project_name'\n",
        "GCS_BUCKET = 'your_bucket_name'\n",
        "GCS_REGION = 'your_region_name'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5R1_iIZLF0PN"
      },
      "outputs": [],
      "source": [
        "# set up the file paths to your data\n",
        "BATCHES_TO_LOAD = ['your-batch-names']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztauDegTGtYZ"
      },
      "outputs": [],
      "source": [
        "#@title Imports and code setup\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import scipy.spatial.distance as distance\n",
        "from sklearn import ensemble, metrics, preprocessing, manifold, decomposition, mixture, linear_model, neighbors\n",
        "import altair as alt\n",
        "import fsspec\n",
        "from google.cloud import storage\n",
        "alt.data_transformers.disable_max_rows()\n",
        "\n",
        "def make_tsne(df):\n",
        "  dist_list = distance.pdist(df, metric=\"cosine\")\n",
        "  dist_square = distance.squareform(dist_list)\n",
        "  tsne = manifold.TSNE(n_components=2, random_state=10, metric=\"precomputed\", init=\"random\")\n",
        "  embedding_tsne = tsne.fit_transform(dist_square)\n",
        "  emb_df = pd.DataFrame(embedding_tsne, index=df.index)\n",
        "  emb_df.columns = ['x', 'y']\n",
        "  emb_df.set_index(['x', 'y'], append=True, inplace=True)\n",
        "  return emb_df.reset_index()\n",
        "\n",
        "\n",
        "def create_parquet_filter(field, values_to_keep):\n",
        "  # Create the filter for all plates\n",
        "  filter_list = []\n",
        "  for p in values_to_keep:\n",
        "    # AND filters are all within one list\n",
        "    # We want an OR filter, so we need a list of lists of tuples\n",
        "    filter_list.append( [(field, '=', p)])\n",
        "\n",
        "  return filter_list\n",
        "\n",
        "\n",
        "def load_parquet_to_emb_df(filepath_list, filter_list=None,\n",
        "                           embedding_name='mean_embedding'):\n",
        "  # Read the new Parquet output\n",
        "  emb_df_list = []\n",
        "  for p in filepath_list:\n",
        "    with fsspec.open(p) as f:\n",
        "      if filter_list:\n",
        "        emb_df_list.append(pd.read_parquet(f, filters=filter_list))\n",
        "      else:\n",
        "        emb_df_list.append(pd.read_parquet(f))\n",
        "\n",
        "  emb_df = pd.concat(emb_df_list)\n",
        "  if len(emb_df) == 0:\n",
        "    raise ValueError('The embedding dataframe is empty, did you use the right filters?')\n",
        "\n",
        "  for col in ['image', 'channel_order']:\n",
        "    if col in emb_df.columns:\n",
        "      emb_df.drop(columns=[col], inplace=True)\n",
        "\n",
        "  # expand the embedding\n",
        "  tmp_df = pd.DataFrame([pd.Series(x) for x in emb_df[embedding_name]])\n",
        "  tmp_df.columns = [str(x) for x in range(192)]\n",
        "  emb_df = pd.concat([emb_df.reset_index(), tmp_df], axis=1)\n",
        "  emb_df.drop(columns=[embedding_name], inplace=True)\n",
        "\n",
        "  # set the index\n",
        "  emb_df.set_index([c for c in emb_df.columns if not c in [str(x) for x in range(192)]], inplace=True)\n",
        "\n",
        "  return emb_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLtu1odmYs-M"
      },
      "source": [
        "# Generate parquet file paths\n",
        "\n",
        "By default, we assume that you want to load the canonical data for one or more batches. Use this code to create the parquet file paths to load.\n",
        "\n",
        "If you have different parquet paths that you want to load, you can always skip these steps and manually define PARQUET_EMB_PATHS as a list of parquet files to open."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThlcY44waaHh"
      },
      "outputs": [],
      "source": [
        "BATCHES_TO_LOAD = ['your-batch-names']\n",
        "DATASET_TO_USE = 'gs://path/to/your/dataset'\n",
        "\n",
        "# The prefix for any well mean files to load\n",
        "EMB_PREFIX = os.path.join(\n",
        "    'you_folder/emb', DATASET_TO_USE, '%s/')\n",
        "# we require any well_mean parquet file paths to contain this\n",
        "WELL_MEAN_STR = 'canon/well_mean_hypnozoite.parquet'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BfrPTNugkXM0"
      },
      "outputs": [],
      "source": [
        "def glob_cloud(bucket, prefix, must_contain_str=None):\n",
        "  \"\"\"Returned files start with gs://[bucket]/[prefix] and contain the must_contain_str if provided.\"\"\"\n",
        "  client = storage.Client()\n",
        "  files_in_dir = [blob.name for blob in client.list_blobs(bucket, prefix=prefix)]\n",
        "  #print(files_in_dir)\n",
        "  if not must_contain_str:\n",
        "    return [os.path.join('gs://%s' % bucket, f) for f in files_in_dir]\n",
        "\n",
        "  ret_val = []\n",
        "  for f in files_in_dir:\n",
        "    if must_contain_str in f:\n",
        "      ret_val.append(os.path.join('gs://%s' % bucket, f))\n",
        "\n",
        "  #print('For %s with %s, found:' % (prefix, must_contain_str))\n",
        "  #print(ret_val)\n",
        "  return ret_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9T0LpCecMQt"
      },
      "outputs": [],
      "source": [
        "#@title Create the list of parquets to load\n",
        "\n",
        "# Pick option 1 or option 2 and leave the other option commented out.\n",
        "\n",
        "# Option 1: Generate canonical paths for your batches above\n",
        "PARQUET_EMB_PATHS = []\n",
        "for b in BATCHES_TO_LOAD:\n",
        "  PARQUET_EMB_PATHS.extend(\n",
        "      glob_cloud(GCS_BUCKET, EMB_PREFIX % b, WELL_MEAN_STR)\n",
        "  )\n",
        "\n",
        "# Option 2: Manually define the set of paths to load\n",
        "#PARQUET_EMB_PATHS = [\n",
        "#    'gs://path/to/your/dataset/well_mean_parquet/filename',\n",
        "#    'gs://path/to/your/dataset/well_mean_parquet/filename',\n",
        "#]\n",
        "\n",
        "print('Planning to load parquet files:\\n\\t%s' % '\\n\\t'.join(PARQUET_EMB_PATHS))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf2nCmSmdSN3"
      },
      "source": [
        "# Load embedding dataframes, generate tSNE coordinates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kv5beU5VEMOW"
      },
      "outputs": [],
      "source": [
        "#@title Optional: filter to specific plates\n",
        "\n",
        "# In practice, these well mean dataframes are fairly small so it's easiest to\n",
        "# just load the whole dataframe\n",
        "filter_list = None\n",
        "print('No filters, loading the whole embedding dataframe.')\n",
        "\n",
        "# BUT, you can always limit the data you load to make things faster.\n",
        "# Some examples of filters\n",
        "# Limit to only plate my_plate\n",
        "#filter_list = create_parquet_filter('plate', ['my_plate'])\n",
        "# Limit to only well my_well (on all the plates)\n",
        "#filter_list = create_parquet_filter('well', ['my_well'])\n",
        "# More on filters here:\n",
        "# https://stackoverflow.com/questions/56522977/using-predicates-to-filter-rows-from-pyarrow-parquet-parquetdataset\n",
        "# You can use AND and OR filters, etc.\n",
        "#print(f'Filtering to {filter_list}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wULGRoV1dM6M"
      },
      "outputs": [],
      "source": [
        "#@title Load all the embeddings into a dataframe\n",
        "emb_df = load_parquet_to_emb_df(PARQUET_EMB_PATHS, filter_list=filter_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1Ccv-o3e6v9"
      },
      "outputs": [],
      "source": [
        "emb_df.head()\n",
        "# The index is the batch/plate/well and the values are all the dimensions\n",
        "# of the mean embedding per well.\n",
        "# There's no metadata yet (like blinded_code or actives)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reaqqUgkbHO-"
      },
      "source": [
        "# Calculate tSNE coordinates and graph\n",
        "\n",
        "This section filters to a subset of data then calculates the tSNE coordinates (i.e. projects the high dimensional embeddings down to 2D in a way to best visualize the distance between elements).\n",
        "\n",
        "Generally you want to calculate the coordinates once, so each well has a position on the graph. Then you want to display the same graph multiple times with different attributes colors so you can judge how things are clustered.\n",
        "\n",
        "As an example, below we:\n",
        "  * Subset on all the wells in two batches except the \"uninfected control\" wells.\n",
        "  * Show the same plot colored by batch, hep_lot, and actives\n",
        "  * Then we can judge the meaning of each 'island' in the plot.\n",
        "\n",
        "Example Conclusion: There are three islands. Using the plots below, I determine that the top right has the active compounds from both batches, while left is the infected controls and inactive compounds from batch 1 which is hep_lot 1 while the bottom island is the infected controls and inactive compounds from batch 2 which is hep_lot 2.\n",
        "\n",
        "Note that the tSNE calculation can take a while with a lot of points.You can take a subset to reduce the tSNE calculation time.\n",
        "\n",
        "If you want to play with different subsets of the data, you can copy and paste this section multiple times into the colab.\n",
        "\n",
        "(I recommend deleting this text and instead typing about your data subset, what you are trying to achieve, and (after you finish) your conclusions.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TePGtVt40QJ"
      },
      "outputs": [],
      "source": [
        "#@title Subset the full embedding dataframe\n",
        "# drop DAPI and NaNs\n",
        "subset_emb_df = emb_df[[str(x) for x in range(64,192)]].copy()\n",
        "subset_emb_df = subset_emb_df.dropna()\n",
        "\n",
        "# For example, you could subset to only the control wells:\n",
        "subset_emb_df = subset_emb_df.query('actives != \"uninfected control\"')\n",
        "\n",
        "# If you have a lot of wells and want you can mix\u0026match your selections.\n",
        "# (Be careful that you stay statistically valid).\n",
        "# One example: Use all the infected control and active control but only\n",
        "# a subset of the sample wells. Make sure you sample randomly.\n",
        "# Here I build both datasets and then concatentate them.\n",
        "control_emb_df = subset_emb_df.query('actives in [\"infected control\", \"active control\"]')\n",
        "some_sample_emb_df = subset_emb_df.query('actives == \"sample\"').sample(1000)\n",
        "subset_emb_df = pd.concat([control_emb_df, some_sample_emb_df])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tEiBmIElSPv"
      },
      "outputs": [],
      "source": [
        "# do a quick validation - is the subset what you expect?\n",
        "subset_emb_df.reset_index().actives.value_counts()\n",
        "\n",
        "# in this case: yep, this has the same number of control wells except the\n",
        "# uninfected control wells are gone, and I've got the 1000 sample wells I asked for."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfN2aZ4aI0vC"
      },
      "outputs": [],
      "source": [
        "# make tsne\n",
        "tsne_df = make_tsne(subset_emb_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBE_AjubodNT"
      },
      "outputs": [],
      "source": [
        "#@title tSNE\n",
        "plot_title = 'Pick an informative name: ex: Color by Batch' #@param\n",
        "plot_width = 1000 #@param\n",
        "plot_height = 600 #@param\n",
        "color_by = 'batch' #@param\n",
        "size_by = 'cp_nuclei' #@param\n",
        "metadata_to_display = ['batch','well', 'plate', 'actives', 'concentration', 'hep_lot','blinded_concept', 'flag_IQCH30', 'flag_Nuclei', 'cp_nuclei','cp_hypnozoite', ] #@param\n",
        "\n",
        "base = alt.Chart(\n",
        "    tsne_df.sort_values(by=color_by,ascending=False),\n",
        "    title=plot_title,\n",
        "    width=plot_width,\n",
        "    height=plot_height,\n",
        ").mark_circle().encode(\n",
        "    alt.X(\n",
        "        'x:Q',\n",
        "        axis=alt.Axis(grid=False),\n",
        "        title='X',\n",
        "    ),\n",
        "    alt.Y(\n",
        "        'y:Q',\n",
        "        axis=alt.Axis(grid=False),\n",
        "        title='Y',\n",
        "    ),\n",
        "    size=alt.Size(size_by, scale=alt.Scale(type='linear')),\n",
        "    color=alt.Color(\n",
        "        color_by,\n",
        "        title=color_by,\n",
        "        sort=['sample', 'active_control', 'infected_control'],\n",
        "    ),\n",
        "    tooltip=[\n",
        "        alt.Tooltip(metadata, title=metadata) for metadata in metadata_to_display]\n",
        ")\n",
        "base.interactive()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkRVzqF3nVaQ"
      },
      "outputs": [],
      "source": [
        "#@title tSNE\n",
        "plot_title = 'Pick an informative name: ex: Color by Hep_Lot' #@param\n",
        "plot_width = 1000 #@param\n",
        "plot_height = 600 #@param\n",
        "color_by = 'hep_lot' #@param\n",
        "size_by = 'cp_nuclei' #@param\n",
        "metadata_to_display = ['batch','well', 'plate', 'actives', 'concentration', 'hep_lot','blinded_concept', 'flag_IQCH30', 'flag_Nuclei', 'cp_nuclei','cp_hypnozoite', ] #@param\n",
        "\n",
        "base = alt.Chart(\n",
        "    tsne_df.sort_values(by=color_by,ascending=False),\n",
        "    title=plot_title,\n",
        "    width=plot_width,\n",
        "    height=plot_height,\n",
        ").mark_circle().encode(\n",
        "    alt.X(\n",
        "        'x:Q',\n",
        "        axis=alt.Axis(grid=False),\n",
        "        title='X',\n",
        "    ),\n",
        "    alt.Y(\n",
        "        'y:Q',\n",
        "        axis=alt.Axis(grid=False),\n",
        "        title='Y',\n",
        "    ),\n",
        "    size=alt.Size(size_by, scale=alt.Scale(type='linear')),\n",
        "    color=alt.Color(\n",
        "        color_by,\n",
        "        title=color_by,\n",
        "        sort=['sample', 'active_control', 'infected_control'],\n",
        "    ),\n",
        "    tooltip=[\n",
        "        alt.Tooltip(metadata, title=metadata) for metadata in metadata_to_display]\n",
        ")\n",
        "base.interactive()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxWBTQK5nVEs"
      },
      "outputs": [],
      "source": [
        "#@title tSNE\n",
        "plot_title = 'Pick an informative name: ex: Color by Actives' #@param\n",
        "plot_width = 1000 #@param\n",
        "plot_height = 600 #@param\n",
        "color_by = 'actives' #@param\n",
        "size_by = 'cp_nuclei' #@param\n",
        "metadata_to_display = ['batch','well', 'plate', 'actives', 'concentration', 'hep_lot','blinded_concept', 'flag_IQCH30', 'flag_Nuclei', 'cp_nuclei','cp_hypnozoite', ] #@param\n",
        "\n",
        "base = alt.Chart(\n",
        "    tsne_df.sort_values(by=color_by,ascending=False),\n",
        "    title=plot_title,\n",
        "    width=plot_width,\n",
        "    height=plot_height,\n",
        ").mark_circle().encode(\n",
        "    alt.X(\n",
        "        'x:Q',\n",
        "        axis=alt.Axis(grid=False),\n",
        "        title='X',\n",
        "    ),\n",
        "    alt.Y(\n",
        "        'y:Q',\n",
        "        axis=alt.Axis(grid=False),\n",
        "        title='Y',\n",
        "    ),\n",
        "    size=alt.Size(size_by, scale=alt.Scale(type='linear')),\n",
        "    color=alt.Color(\n",
        "        color_by,\n",
        "        title=color_by,\n",
        "        sort=['sample', 'active_control', 'infected_control'],\n",
        "    ),\n",
        "    tooltip=[\n",
        "        alt.Tooltip(metadata, title=metadata) for metadata in metadata_to_display]\n",
        ")\n",
        "base.interactive()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1UCVwyjlUCDXIWdJUdckxkcuz_JcReMgc",
          "timestamp": 1680559346383
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
