{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21nDY-36FQ-E"
      },
      "source": [
        "# Create a tensorstore and view thumbnails\n",
        "\n",
        "In this colab, we will use image_grid to lay out the example images into a tensorstore and then use this to draw patch thumbnails from the tensorstore.\n",
        "\n",
        "The image_grid module is built on top of tensorstore as a straightforward way to layout the grid of images in the tensorstore. In our case, we have a set of microscope images from 384 well plates. We want our 2D \"map\" to lay out our image so that, if you zoom all the way out, you see a grid of the plates and as you zoom in, each well and site are where you'd expect. In this analogy, you can think of the different stains (colors) as layers in the map.\n",
        "\n",
        "The image_grid module is responsible for laying out the hierarchy of the axes, while tensorstore is the name of the datastorage module itself. In other words, image_grid is a wrapper on top of tensorstore to help make this gridding easier, particuarly with the idea of plates/wells/sites in mind."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CpEP10l3hqw"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/google/cell_img\n",
        "!pip install --quiet -e cell_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpfbCX3WVD2b"
      },
      "outputs": [],
      "source": [
        "#@title Restart your colab kernel after the installs above, then run this\n",
        "\n",
        "import cell_img\n",
        "from cell_img.common import io_lib\n",
        "from cell_img.image_grid import ts_write_main_lib\n",
        "from cell_img.image_grid import ts_write_main\n",
        "from cell_img.malaria_liver import metadata_lib\n",
        "\n",
        "import fsspec\n",
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgq9WGjwV13Z"
      },
      "outputs": [],
      "source": [
        "# Will not be needed for the public Google Research Cloud Bucket\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doHxPrNPsmOS"
      },
      "outputs": [],
      "source": [
        "DATA_ROOT = 'gs://path/to/your/data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfM4VXdG1G6H"
      },
      "outputs": [],
      "source": [
        "#GCS_PROJECT = 'your_project'\n",
        "#GCS_BUCKET = 'your_bucket'\n",
        "#GCS_REGION = 'your_region'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdKbFqS2zr8g"
      },
      "source": [
        "# Inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgEPR5IzVUyb"
      },
      "outputs": [],
      "source": [
        "# Path for where to create the tensorstore instance\n",
        "TENSORSTORE_PATH = os.path.join(DATA_ROOT, 'tensorstore')\n",
        "\n",
        "# Path for where to find the CSVs with the information needed to create the\n",
        "# tensorstore: image paths and where, within the image_grid, to place each image.\n",
        "METADATA_ROOT = os.path.join(DATA_ROOT, 'tensorstore/metadata')\n",
        "TS_CSV_FOLDER = 'tensorstore'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWKyWnBDZeIC"
      },
      "outputs": [],
      "source": [
        "# Get the list of CSVs with images to put into tensorstore\n",
        "image_csv_list = ['gs://' + x.path for x in fsspec.open_files(\n",
        "    os.path.join(METADATA_ROOT, TS_CSV_FOLDER, '*.csv'))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vwhg_Fi9dpLy"
      },
      "outputs": [],
      "source": [
        "# Validation 1 : Which files are we using?\n",
        "print('The following files will be used:\\n   %s' % '\\n   '.join(image_csv_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUxtma4Fdl46"
      },
      "outputs": [],
      "source": [
        "# Validation 2: Look at one CSV to see the columns\n",
        "df = pd.read_csv(image_csv_list[0], dtype=str)\n",
        "\n",
        "df.sample(5)\n",
        "\n",
        "# Each row is one image to be added to the image_grid\n",
        "# The image_grid can be thought of as a large map. We set it up to put each\n",
        "# plate/well/site into a large 2D grid, then use channel as the third dimension,\n",
        "# like layers in a map.\n",
        "\n",
        "# plate_uid, well, site and channel help users understand the image location\n",
        "# channel is which stain (color) the image is in, used for the third dimension\n",
        "#   in the image_grid.\n",
        "# image_path indicates where the file containing the image is found.\n",
        "# plate_row, plate_col, well_row, well_col, site_row and site_col all work to\n",
        "#   identify where in the large map this particular image should be placed.\n",
        "#   This is done by uses them as the x_axis_wrap and y_axis_wrap in the\n",
        "#   image_grid ts_write_main_lib function below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8r126wv6Ty4O"
      },
      "outputs": [],
      "source": [
        "# Validation 3: Check that the image dimensions are the same in every CSV\n",
        "first_csv_shape = None\n",
        "\n",
        "for ic in image_csv_list:\n",
        "  image_df = io_lib.read_csv(ic, dtype=str)\n",
        "  for x in [0]:\n",
        "    img_path = image_df.image_path.iloc[x]\n",
        "    img_arr = io_lib.read_image(img_path)\n",
        "    print(img_arr.shape, img_path)\n",
        "    if not first_csv_shape:\n",
        "      first_csv_shape = img_arr.shape\n",
        "    elif img_arr.shape != first_csv_shape:\n",
        "      raise ValueError(\n",
        "          'The first csv had shape %s,\\n but a test image from %s\\n has shape %s instead.' % (\n",
        "              first_csv_shape, img_arr.shape))\n",
        "\n",
        "print('Image shape test successful!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD_XQchX0lHB"
      },
      "source": [
        "# Run Cloud DataFlow job to create the tensorstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "402DJPXw0khB"
      },
      "outputs": [],
      "source": [
        "options = ts_write_main.get_pipeline_options(GCS_PROJECT, GCS_BUCKET, GCS_REGION)\n",
        "\n",
        "pipeline_result = ts_write_main_lib.run_write_to_ts_pipeline(\n",
        "    tensorstore_path=TENSORSTORE_PATH,\n",
        "    create_new_tensorstore=True,\n",
        "    allow_expansion_of_tensorstore=False,\n",
        "    image_metadata_path=image_csv_list,\n",
        "    image_path_col='image_path',\n",
        "    axes=['Y', 'X', 'channel'],\n",
        "    x_axis_wrap=['plate_col', 'well_col', 'site_col'],\n",
        "    y_axis_wrap=['plate_row', 'well_row', 'site_row'],\n",
        "    pipeline_options=options)\n",
        "\n",
        "url = ('https://console.cloud.google.com/dataflow/jobs/%s/%s?project=%s' %\n",
        "       (pipeline_result._job.location, pipeline_result._job.id,\n",
        "        pipeline_result._job.projectId))\n",
        "print(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Z2h2FL9XWhi"
      },
      "source": [
        "If you later wanted to expand this tensorstore with new images, the command would be:\n",
        "\n",
        "```\n",
        "pipeline_result = ts_write_main_lib.run_write_to_ts_pipeline(\n",
        "    tensorstore_path=TENSORSTORE_PATH,\n",
        "    create_new_tensorstore=False,\n",
        "    allow_expansion_of_tensorstore=False,\n",
        "    image_metadata_path=image_csv_list,\n",
        "    image_path_col='image_path',\n",
        "    axes=None,\n",
        "    x_axis_wrap=False,\n",
        "    y_axis_wrap=False,\n",
        "    pipeline_options=options)\n",
        "```\n",
        "\n",
        "A few notes for expanding, as opposed to creating:\n",
        "* \"allow_expandsion_of_tensorstore\" is whether the 2D \"map\" is allowed to grow. If you know your new images are within the boundaries of the existing map, leave this set to False to avoid accidentally expanding the map due to typos. Often, however, you may be adding new rows or columns that push your map bigger. In this, set this value to be True.\n",
        "* Note that in this call the axes, x_axis_wrap, and y_axis_wrap values are not passed in. When adding to an existing image_grid, you use the already-defined axes from the creation call."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2QUFYkkk_r0"
      },
      "source": [
        "# Visualizing the image_grid\n",
        "\n",
        "[Neuroglancer](https://github.com/google/neuroglancer) is a great way to visualize your whole grid of images, with a user interface somewhat like Google Maps, that lets you zoom and turn layers on and off. The tensorstore set up by image_grid is designed to be used by Neuroglancer.\n",
        "\n",
        "You can also use the tensorstore to grab patch images given the location of the patch (e.g. plate, well, site, x, y). This example data has the metadata files set up to be used by the cell_img thumbnail code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9H6auwYlt-P"
      },
      "outputs": [],
      "source": [
        "# set up the object to create images based on metadata\n",
        "\n",
        "# Set up the alignment between our channel names and RGB\n",
        "CHANNEL_TO_RGB = ['w3', 'w2', 'w1']\n",
        "meta_ts = metadata_lib.MetadataIndex(\n",
        "    TENSORSTORE_PATH, CHANNEL_TO_RGB, METADATA_ROOT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96otdrVcuJwV"
      },
      "outputs": [],
      "source": [
        "# Load the example patch csv for testing\n",
        "# read the CSV with dtype str to preserve string formatting on plates and sites.\n",
        "example_df = pd.read_csv(\n",
        "    os.path.join(DATA_ROOT, 'emb_data/example_patches.csv'),\n",
        "    dtype=str)\n",
        "# convert the center_row and center_col to ints\n",
        "example_df['center_row'] = example_df['center_row'].astype(int)\n",
        "example_df['center_col'] = example_df['center_col'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suOftr8B0RRZ"
      },
      "outputs": [],
      "source": [
        "# Look at the examples - what are the columns, what does the data look like?\n",
        "example_df.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1fUF6qF0TVe"
      },
      "outputs": [],
      "source": [
        "# Look at the sample, how many parasites of each life cycle stage are available?\n",
        "example_df.stage_result.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZK9ugsg0Vsr"
      },
      "outputs": [],
      "source": [
        "# Look at the examples, how many from each plate do we have?\n",
        "example_df.plate.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQzOWQ0W0Opa"
      },
      "outputs": [],
      "source": [
        "# First, let's show some hypnozoite examples\n",
        "# This function takes in a dataframe with batch/plate/well/site and columns\n",
        "# for the x/y within the site (center_col and center_row in this case),\n",
        "# grabs thumbnails for each row and displays them.\n",
        "_ = meta_ts.contact_sheet_for_df(\n",
        "    example_df=example_df.query('stage_result == \"hypnozoite\"').sample(6),\n",
        "    patch_size=50, ncols=3, nrows=2,\n",
        "    name_for_x_col='center_col', name_for_y_col='center_row')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpGtoCMT1qHw"
      },
      "outputs": [],
      "source": [
        "# The schizonts are bigger, let's show a larger patch size for those\n",
        "# (you'll see that the blue liver nuclei in the patches below are much smaller\n",
        "# than the ones in the patches above, because each patch here is a 150x150\n",
        "# square instead of the 50x50 above.)\n",
        "_ = meta_ts.contact_sheet_for_df(\n",
        "    example_df=example_df.query('stage_result == \"schizont\"').sample(4),\n",
        "    patch_size=150, ncols=2, nrows=2,\n",
        "    name_for_x_col='center_col', name_for_y_col='center_row')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nf2cprmTmm_q"
      },
      "source": [
        "# Examining / Validating the image_grid\n",
        "\n",
        "This section reads in the image_grid you have created to help understand the setup (and these tools are useful in debugging).\n",
        "\n",
        "For example, an error might be:\n",
        "\n",
        "```\n",
        "ValueError: Cannot write the new images without expanding the tensorstore first.\n",
        "Set flag allow_expansion_of_tensorstore to True.\n",
        "axis_to_values_to_add={'plate_col': ['11']}\n",
        "```\n",
        "\n",
        "This error indicates that you are trying to expand the rectangle of the tensorstore, the 2D \"map\" (so, if you zoom way way out, the full area of the rectangle would get bigger). In this example case, the rectangle width is defined by the plate_col, which is set to be the last 2 digits of the plate. And then rectangle height is defined by the plate_row, which is the first digits of the plate.\n",
        "\n",
        "This error message is saying that there is currently not a column \"11\" in your 2D map, and if you want to let this plate into the grid in the space where it should be, you'll need to set the expansion flag to true. Note that this new plate_col will be added to the far right of the existing map. So even if plate_col 10 and 12 exist before this new plate is added, plate_col 11 cannot go between them - the expansion must always be down and to the right, existing data cannot be shifted.\n",
        "\n",
        "Looking at the existing_dataset.spec below can show you the values that currently exist in the tensorstore so you can debug whether your data should expand the store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdK2deX3baLI"
      },
      "outputs": [],
      "source": [
        "from cell_img.image_grid import downsample_lib\n",
        "from cell_img.image_grid import ts_metadata_lib\n",
        "from cell_img.image_grid import ts_write_lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqOQpvvfbWEj"
      },
      "outputs": [],
      "source": [
        "# Repeating the code in _maybe_expand_tensorstore in colab\n",
        "tensorstore_path_s0 = downsample_lib.join_downsample_level_to_path(TENSORSTORE_PATH, 0)\n",
        "spec_without_metadata = ts_write_lib.create_spec_from_path(tensorstore_path_s0)\n",
        "existing_dataset = ts_write_lib.open_existing_tensorstore(spec_without_metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FU8R0g3XDLT8"
      },
      "outputs": [],
      "source": [
        "existing_dataset.spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtdMyv3BDM-u"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1lfSTMTNmTmLtjTOuzKdhcfP8R4emIhBQ",
          "timestamp": 1680294535806
        },
        {
          "file_id": "1O1X0cp2-c902X-pRpTAPjaAUhmpvI_01",
          "timestamp": 1679348855451
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
